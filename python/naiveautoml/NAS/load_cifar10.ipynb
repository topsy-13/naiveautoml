{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import time\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from itertools import product\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load CIFAR-10 dataset\n",
    "\n",
    "The CIFAR-10 dataset consists of images that are 32x32 pixels in size and have 3 color channels (Red, Green, Blue)  \n",
    "Each image in the CIFAR-10 dataset is represented as a 1D array of length 3072 (32 * 32 * 3).\n",
    "The first 1024 values correspond to the Red channel, the next 1024 values correspond to the Green channel, and the last 1024 values correspond to the Blue channel.\n",
    "\n",
    "The common format for image data in deep learning frameworks like PyTorch is:\n",
    "\n",
    "Shape: (num_samples, channels, height, width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 10000\n",
      "20000 20000\n",
      "30000 30000\n",
      "40000 40000\n",
      "50000 50000\n",
      "(50000, 3072) (50000,)\n"
     ]
    }
   ],
   "source": [
    "# Initialize variables\n",
    "X_train, y_train = [], []\n",
    "X_test, y_test = [], []\n",
    "\n",
    "# Load all the paths of the pickle files\n",
    "cifar_path = \"CIFAR-10\"\n",
    "files_path = os.listdir(cifar_path)\n",
    "\n",
    "# Load training data\n",
    "for file in files_path: \n",
    "  filepath = os.path.join(cifar_path, file)\n",
    "  if file.startswith(\"data_batch\"):\n",
    "    temp_dict = unpickle(filepath)\n",
    "    X_train.extend(temp_dict[b'data'])\n",
    "    y_train.extend(temp_dict[b'labels'])\n",
    "    print(len(X_train), len(y_train))\n",
    "\n",
    "# Load testing data\n",
    "for file in files_path:\n",
    "    filepath = os.path.join(cifar_path, file)\n",
    "    if file.startswith(\"test_batch\"):\n",
    "        temp_dict = unpickle(filepath)\n",
    "        X_test.append(temp_dict[b'data'])\n",
    "        y_test.extend(temp_dict[b'labels'])\n",
    "\n",
    "\n",
    "\n",
    "# Turn into numpy array \n",
    "X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "X_test, y_test = np.array(X_test), np.array(y_test)\n",
    "\n",
    "\n",
    "# Reshape the data\n",
    "# X_train = np.vstack(X_train).reshape(-1, 3, 32, 32) #-1 is the number of samples/images, 3 is the channnels, 32 is the height and 32 is the width\n",
    "X_train = np.vstack(X_train)\n",
    "\n",
    "# X_test = np.vstack(X_test).reshape(-1, 3, 32, 32)\n",
    "X_test= np.vstack(X_test)\n",
    "\n",
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((40000, 3072), (10000, 3072))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create X_val set\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_scaled, y_train, test_size=0.2, random_state=13)\n",
    "X_train.shape, X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Select an image index\n",
    "# index = 13\n",
    "\n",
    "# # Get the image\n",
    "# image = X_train[index]\n",
    "\n",
    "# # Plot it\n",
    "# plt.figure(figsize=(1, 1))  \n",
    "# plt.imshow(image.reshape(0, 2, 3, 1))\n",
    "# plt.axis(\"off\")\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For PyTorch: Image data in the format (num_samples, channels, height, width) for training and inference.  \n",
    "For Visualization: transpose(1, 2, 0) is required to convert the image to the format (height, width, channels) when using plt.imshow()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Search Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fibonacci(n):\n",
    "    fib_sequence = [0, 1]\n",
    "    while True:\n",
    "        next_fib = fib_sequence[-1] + fib_sequence[-2]\n",
    "        if next_fib > n:\n",
    "            break\n",
    "        fib_sequence.append(next_fib)\n",
    "    \n",
    "    return fib_sequence[2:]  # Exclude 0 and 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de configuraciones: 60\n"
     ]
    }
   ],
   "source": [
    "n_hidden_layers = fibonacci(5)\n",
    "n_neurons_x_layer = [50, 100, 200, 500, 1000]\n",
    "learning_rate = [10**-3, 10**-4, 10**-5]\n",
    "activation = 'relu'\n",
    "solver='adam'\n",
    "\n",
    "# se hacen todas las combinaciones\n",
    "configurations = list(product(n_hidden_layers, n_neurons_x_layer, learning_rate))\n",
    "print('Total de configuraciones:', len(configurations))\n",
    "\n",
    "configuration_results = {\n",
    "    'hidden_layers': [],\n",
    "    'n_neurons': [],\n",
    "    'learning_rate': [],\n",
    "    'train_time': [],\n",
    "    'train_score': [],\n",
    "    'val_score': [],  # stores only the last validation score after each epoch? \n",
    "    'test_score': [],  # stores only the last validation score after each epoch? \n",
    "    'confusion_matrices': [],\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 75\n",
      "Hidden Layers: 1, # Neurons: 50, Learning rate: 0.001\n",
      "Training Time: 1.1319 seconds\n",
      "Validation Accuracy: 0.4211\n",
      "2 / 75\n",
      "Hidden Layers: 1, # Neurons: 50, Learning rate: 0.0001\n",
      "Training Time: 1.1173 seconds\n",
      "Validation Accuracy: 0.3777\n",
      "3 / 75\n",
      "Hidden Layers: 1, # Neurons: 50, Learning rate: 1e-05\n",
      "Training Time: 1.1136 seconds\n",
      "Validation Accuracy: 0.2277\n",
      "4 / 75\n",
      "Hidden Layers: 1, # Neurons: 100, Learning rate: 0.001\n",
      "Training Time: 1.8529 seconds\n",
      "Validation Accuracy: 0.4241\n",
      "5 / 75\n",
      "Hidden Layers: 1, # Neurons: 100, Learning rate: 0.0001\n",
      "Training Time: 1.8071 seconds\n",
      "Validation Accuracy: 0.3980\n",
      "6 / 75\n",
      "Hidden Layers: 1, # Neurons: 100, Learning rate: 1e-05\n",
      "Training Time: 1.7794 seconds\n",
      "Validation Accuracy: 0.2546\n",
      "7 / 75\n",
      "Hidden Layers: 1, # Neurons: 200, Learning rate: 0.001\n",
      "Training Time: 3.0976 seconds\n",
      "Validation Accuracy: 0.4303\n",
      "8 / 75\n",
      "Hidden Layers: 1, # Neurons: 200, Learning rate: 0.0001\n",
      "Training Time: 3.2105 seconds\n",
      "Validation Accuracy: 0.4150\n",
      "9 / 75\n",
      "Hidden Layers: 1, # Neurons: 200, Learning rate: 1e-05\n",
      "Training Time: 3.1383 seconds\n",
      "Validation Accuracy: 0.3028\n",
      "10 / 75\n",
      "Hidden Layers: 1, # Neurons: 500, Learning rate: 0.001\n",
      "Training Time: 7.6843 seconds\n",
      "Validation Accuracy: 0.4080\n",
      "11 / 75\n",
      "Hidden Layers: 1, # Neurons: 500, Learning rate: 0.0001\n",
      "Training Time: 7.7540 seconds\n",
      "Validation Accuracy: 0.4390\n",
      "12 / 75\n",
      "Hidden Layers: 1, # Neurons: 500, Learning rate: 1e-05\n",
      "Training Time: 7.7663 seconds\n",
      "Validation Accuracy: 0.3197\n",
      "13 / 75\n",
      "Hidden Layers: 1, # Neurons: 1000, Learning rate: 0.001\n",
      "Training Time: 15.0291 seconds\n",
      "Validation Accuracy: 0.4039\n",
      "14 / 75\n",
      "Hidden Layers: 1, # Neurons: 1000, Learning rate: 0.0001\n",
      "Training Time: 21.1605 seconds\n",
      "Validation Accuracy: 0.4552\n",
      "15 / 75\n",
      "Hidden Layers: 1, # Neurons: 1000, Learning rate: 1e-05\n",
      "Training Time: 18.4323 seconds\n",
      "Validation Accuracy: 0.3609\n",
      "16 / 75\n",
      "Hidden Layers: 2, # Neurons: 50, Learning rate: 0.001\n",
      "Training Time: 1.3104 seconds\n",
      "Validation Accuracy: 0.4153\n",
      "17 / 75\n",
      "Hidden Layers: 2, # Neurons: 50, Learning rate: 0.0001\n",
      "Training Time: 1.2837 seconds\n",
      "Validation Accuracy: 0.3666\n",
      "18 / 75\n",
      "Hidden Layers: 2, # Neurons: 50, Learning rate: 1e-05\n",
      "Training Time: 1.3359 seconds\n",
      "Validation Accuracy: 0.2055\n",
      "19 / 75\n",
      "Hidden Layers: 2, # Neurons: 100, Learning rate: 0.001\n",
      "Training Time: 2.1212 seconds\n",
      "Validation Accuracy: 0.4219\n",
      "20 / 75\n",
      "Hidden Layers: 2, # Neurons: 100, Learning rate: 0.0001\n",
      "Training Time: 2.1398 seconds\n",
      "Validation Accuracy: 0.3972\n",
      "21 / 75\n",
      "Hidden Layers: 2, # Neurons: 100, Learning rate: 1e-05\n",
      "Training Time: 2.0930 seconds\n",
      "Validation Accuracy: 0.2502\n",
      "22 / 75\n",
      "Hidden Layers: 2, # Neurons: 200, Learning rate: 0.001\n",
      "Training Time: 3.6979 seconds\n",
      "Validation Accuracy: 0.4566\n",
      "23 / 75\n",
      "Hidden Layers: 2, # Neurons: 200, Learning rate: 0.0001\n",
      "Training Time: 3.6157 seconds\n",
      "Validation Accuracy: 0.4252\n",
      "24 / 75\n",
      "Hidden Layers: 2, # Neurons: 200, Learning rate: 1e-05\n",
      "Training Time: 3.5093 seconds\n",
      "Validation Accuracy: 0.2929\n",
      "25 / 75\n",
      "Hidden Layers: 2, # Neurons: 500, Learning rate: 0.001\n",
      "Training Time: 9.5133 seconds\n",
      "Validation Accuracy: 0.4517\n",
      "26 / 75\n",
      "Hidden Layers: 2, # Neurons: 500, Learning rate: 0.0001\n",
      "Training Time: 9.9208 seconds\n",
      "Validation Accuracy: 0.4470\n",
      "27 / 75\n",
      "Hidden Layers: 2, # Neurons: 500, Learning rate: 1e-05\n",
      "Training Time: 9.6372 seconds\n",
      "Validation Accuracy: 0.3333\n",
      "28 / 75\n",
      "Hidden Layers: 2, # Neurons: 1000, Learning rate: 0.001\n",
      "Training Time: 20.3810 seconds\n",
      "Validation Accuracy: 0.4611\n",
      "29 / 75\n",
      "Hidden Layers: 2, # Neurons: 1000, Learning rate: 0.0001\n",
      "Training Time: 21.1667 seconds\n",
      "Validation Accuracy: 0.4629\n",
      "30 / 75\n",
      "Hidden Layers: 2, # Neurons: 1000, Learning rate: 1e-05\n",
      "Training Time: 21.5836 seconds\n",
      "Validation Accuracy: 0.3798\n",
      "31 / 75\n",
      "Hidden Layers: 3, # Neurons: 50, Learning rate: 0.001\n",
      "Training Time: 1.2958 seconds\n",
      "Validation Accuracy: 0.4012\n",
      "32 / 75\n",
      "Hidden Layers: 3, # Neurons: 50, Learning rate: 0.0001\n",
      "Training Time: 1.2975 seconds\n",
      "Validation Accuracy: 0.3518\n",
      "33 / 75\n",
      "Hidden Layers: 3, # Neurons: 50, Learning rate: 1e-05\n",
      "Training Time: 1.2959 seconds\n",
      "Validation Accuracy: 0.1503\n",
      "34 / 75\n",
      "Hidden Layers: 3, # Neurons: 100, Learning rate: 0.001\n",
      "Training Time: 2.0265 seconds\n",
      "Validation Accuracy: 0.4276\n",
      "35 / 75\n",
      "Hidden Layers: 3, # Neurons: 100, Learning rate: 0.0001\n",
      "Training Time: 2.0142 seconds\n",
      "Validation Accuracy: 0.3905\n",
      "36 / 75\n",
      "Hidden Layers: 3, # Neurons: 100, Learning rate: 1e-05\n",
      "Training Time: 2.0224 seconds\n",
      "Validation Accuracy: 0.2296\n",
      "37 / 75\n",
      "Hidden Layers: 3, # Neurons: 200, Learning rate: 0.001\n",
      "Training Time: 3.5122 seconds\n",
      "Validation Accuracy: 0.4321\n",
      "38 / 75\n",
      "Hidden Layers: 3, # Neurons: 200, Learning rate: 0.0001\n",
      "Training Time: 3.5419 seconds\n",
      "Validation Accuracy: 0.4175\n",
      "39 / 75\n",
      "Hidden Layers: 3, # Neurons: 200, Learning rate: 1e-05\n",
      "Training Time: 3.6190 seconds\n",
      "Validation Accuracy: 0.2673\n",
      "40 / 75\n",
      "Hidden Layers: 3, # Neurons: 500, Learning rate: 0.001\n",
      "Training Time: 10.9144 seconds\n",
      "Validation Accuracy: 0.4475\n",
      "41 / 75\n",
      "Hidden Layers: 3, # Neurons: 500, Learning rate: 0.0001\n",
      "Training Time: 11.1861 seconds\n",
      "Validation Accuracy: 0.4604\n",
      "42 / 75\n",
      "Hidden Layers: 3, # Neurons: 500, Learning rate: 1e-05\n",
      "Training Time: 11.2683 seconds\n",
      "Validation Accuracy: 0.3455\n",
      "43 / 75\n",
      "Hidden Layers: 3, # Neurons: 1000, Learning rate: 0.001\n",
      "Training Time: 32.8990 seconds\n",
      "Validation Accuracy: 0.4328\n",
      "44 / 75\n",
      "Hidden Layers: 3, # Neurons: 1000, Learning rate: 0.0001\n",
      "Training Time: 32.8675 seconds\n",
      "Validation Accuracy: 0.4662\n",
      "45 / 75\n",
      "Hidden Layers: 3, # Neurons: 1000, Learning rate: 1e-05\n",
      "Training Time: 27.5289 seconds\n",
      "Validation Accuracy: 0.3799\n",
      "46 / 75\n",
      "Hidden Layers: 5, # Neurons: 50, Learning rate: 0.001\n",
      "Training Time: 1.3080 seconds\n",
      "Validation Accuracy: 0.4059\n",
      "47 / 75\n",
      "Hidden Layers: 5, # Neurons: 50, Learning rate: 0.0001\n",
      "Training Time: 1.3015 seconds\n",
      "Validation Accuracy: 0.3263\n",
      "48 / 75\n",
      "Hidden Layers: 5, # Neurons: 50, Learning rate: 1e-05\n",
      "Training Time: 1.2926 seconds\n",
      "Validation Accuracy: 0.1422\n",
      "49 / 75\n",
      "Hidden Layers: 5, # Neurons: 100, Learning rate: 0.001\n",
      "Training Time: 2.1967 seconds\n",
      "Validation Accuracy: 0.4274\n",
      "50 / 75\n",
      "Hidden Layers: 5, # Neurons: 100, Learning rate: 0.0001\n",
      "Training Time: 2.1857 seconds\n",
      "Validation Accuracy: 0.3817\n",
      "51 / 75\n",
      "Hidden Layers: 5, # Neurons: 100, Learning rate: 1e-05\n",
      "Training Time: 2.1507 seconds\n",
      "Validation Accuracy: 0.2210\n",
      "52 / 75\n",
      "Hidden Layers: 5, # Neurons: 200, Learning rate: 0.001\n",
      "Training Time: 3.8690 seconds\n",
      "Validation Accuracy: 0.4378\n",
      "53 / 75\n",
      "Hidden Layers: 5, # Neurons: 200, Learning rate: 0.0001\n",
      "Training Time: 3.8732 seconds\n",
      "Validation Accuracy: 0.4234\n",
      "54 / 75\n",
      "Hidden Layers: 5, # Neurons: 200, Learning rate: 1e-05\n",
      "Training Time: 3.8462 seconds\n",
      "Validation Accuracy: 0.2671\n",
      "55 / 75\n",
      "Hidden Layers: 5, # Neurons: 500, Learning rate: 0.001\n",
      "Training Time: 13.5715 seconds\n",
      "Validation Accuracy: 0.4426\n",
      "56 / 75\n",
      "Hidden Layers: 5, # Neurons: 500, Learning rate: 0.0001\n",
      "Training Time: 13.6516 seconds\n",
      "Validation Accuracy: 0.4475\n",
      "57 / 75\n",
      "Hidden Layers: 5, # Neurons: 500, Learning rate: 1e-05\n",
      "Training Time: 13.7912 seconds\n",
      "Validation Accuracy: 0.3311\n",
      "58 / 75\n",
      "Hidden Layers: 5, # Neurons: 1000, Learning rate: 0.001\n",
      "Training Time: 39.8274 seconds\n",
      "Validation Accuracy: 0.4426\n",
      "59 / 75\n",
      "Hidden Layers: 5, # Neurons: 1000, Learning rate: 0.0001\n",
      "Training Time: 44.3580 seconds\n",
      "Validation Accuracy: 0.4659\n",
      "60 / 75\n",
      "Hidden Layers: 5, # Neurons: 1000, Learning rate: 1e-05\n",
      "Training Time: 47.5655 seconds\n",
      "Validation Accuracy: 0.3731\n",
      "61 / 75\n",
      "Hidden Layers: 8, # Neurons: 50, Learning rate: 0.001\n",
      "Training Time: 1.6415 seconds\n",
      "Validation Accuracy: 0.4009\n",
      "62 / 75\n",
      "Hidden Layers: 8, # Neurons: 50, Learning rate: 0.0001\n",
      "Training Time: 1.5631 seconds\n",
      "Validation Accuracy: 0.3187\n",
      "63 / 75\n",
      "Hidden Layers: 8, # Neurons: 50, Learning rate: 1e-05\n",
      "Training Time: 1.5376 seconds\n",
      "Validation Accuracy: 0.0990\n",
      "64 / 75\n",
      "Hidden Layers: 8, # Neurons: 100, Learning rate: 0.001\n",
      "Training Time: 2.6277 seconds\n",
      "Validation Accuracy: 0.4201\n",
      "65 / 75\n",
      "Hidden Layers: 8, # Neurons: 100, Learning rate: 0.0001\n",
      "Training Time: 2.6161 seconds\n",
      "Validation Accuracy: 0.3823\n",
      "66 / 75\n",
      "Hidden Layers: 8, # Neurons: 100, Learning rate: 1e-05\n",
      "Training Time: 2.5950 seconds\n",
      "Validation Accuracy: 0.1583\n",
      "67 / 75\n",
      "Hidden Layers: 8, # Neurons: 200, Learning rate: 0.001\n",
      "Training Time: 4.8129 seconds\n",
      "Validation Accuracy: 0.4358\n",
      "68 / 75\n",
      "Hidden Layers: 8, # Neurons: 200, Learning rate: 0.0001\n",
      "Training Time: 4.8288 seconds\n",
      "Validation Accuracy: 0.4128\n",
      "69 / 75\n",
      "Hidden Layers: 8, # Neurons: 200, Learning rate: 1e-05\n",
      "Training Time: 4.7933 seconds\n",
      "Validation Accuracy: 0.2347\n",
      "70 / 75\n",
      "Hidden Layers: 8, # Neurons: 500, Learning rate: 0.001\n",
      "Training Time: 19.2474 seconds\n",
      "Validation Accuracy: 0.4270\n",
      "71 / 75\n",
      "Hidden Layers: 8, # Neurons: 500, Learning rate: 0.0001\n",
      "Training Time: 19.5267 seconds\n",
      "Validation Accuracy: 0.4483\n",
      "72 / 75\n",
      "Hidden Layers: 8, # Neurons: 500, Learning rate: 1e-05\n",
      "Training Time: 19.3007 seconds\n",
      "Validation Accuracy: 0.3287\n",
      "73 / 75\n",
      "Hidden Layers: 8, # Neurons: 1000, Learning rate: 0.001\n",
      "Training Time: 62.8900 seconds\n",
      "Validation Accuracy: 0.4135\n",
      "74 / 75\n",
      "Hidden Layers: 8, # Neurons: 1000, Learning rate: 0.0001\n",
      "Training Time: 58.5535 seconds\n",
      "Validation Accuracy: 0.4592\n",
      "75 / 75\n",
      "Hidden Layers: 8, # Neurons: 1000, Learning rate: 1e-05\n",
      "Training Time: 58.3691 seconds\n",
      "Validation Accuracy: 0.3731\n"
     ]
    }
   ],
   "source": [
    "for i, (h, n, lr) in enumerate(configurations):\n",
    "    print(i + 1, '/', len(configurations))\n",
    "    print('Hidden Layers: {}, # Neurons: {}, Learning rate: {}'.format(h, n, lr))\n",
    "    # definir estructura de neurona\n",
    "    neuron_structure = (np.ones(h) * n).astype(int)\n",
    "\n",
    "    # Entrenar NN\n",
    "    mlp = MLPClassifier(\n",
    "        hidden_layer_sizes=(neuron_structure),\n",
    "        activation='relu',\n",
    "        solver='adam',\n",
    "        learning_rate_init=lr\n",
    "    )\n",
    "\n",
    "    # Start timing\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Train for one epoch\n",
    "    mlp.partial_fit(X_train, y_train, classes=np.unique(y_train))\n",
    "\n",
    "    # Calculate time taken\n",
    "    total_train_time = time.time() - start_time\n",
    "    # Calculate accuracies\n",
    "    train_accuracy = mlp.score(X_train, y_train)\n",
    "    val_accuracy = mlp.score(X_val, y_val)\n",
    "    y_val_pred = mlp.predict(X_val)  # Predict once\n",
    "\n",
    "    # Confusion matrix\n",
    "    best_cm = confusion_matrix(y_val, y_val_pred)\n",
    "\n",
    "    # Calculate test accuracy\n",
    "    test_accuracy = mlp.score(X_test, y_test)\n",
    "\n",
    "    # Print results\n",
    "    print(f\"Training Time: {total_train_time:.4f} seconds\")\n",
    "    # print(f\"Training Accuracy: {train_accuracy:.4f}\")\n",
    "    print(f\"Validation Accuracy: {val_accuracy:.4f}\")\n",
    "    # print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "    # print(\"Confusion Matrix:\\n\", best_cm)\n",
    "\n",
    "    # Se almacenan los resultados en el dict\n",
    "    configuration_results['hidden_layers'].append(h)\n",
    "    configuration_results['n_neurons'].append(n)\n",
    "    configuration_results['learning_rate'].append(lr)\n",
    "    configuration_results['train_time'].append(total_train_time)\n",
    "    configuration_results['train_score'].append(train_accuracy)\n",
    "    configuration_results['val_score'].append(val_accuracy)\n",
    "    configuration_results['test_score'].append(test_accuracy)\n",
    "    configuration_results['confusion_matrices'].append(best_cm)\n",
    "\n",
    "configurations_df = pd.DataFrame(configuration_results)\n",
    "configurations_df.to_excel('One_Epoch_Results.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configurations_df.to_excel('One_Epoch_Results.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "configurations_df = pd.DataFrame(configuration_results)\n",
    "configurations_df['ID'] = configurations_df['hidden_layers'].astype(str) + '_' + configurations_df['n_neurons'].astype(str) + '_' + configurations_df['learning_rate'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "hidden_layers",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "n_neurons",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "learning_rate",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "train_time",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "train_score",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "val_score",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "test_score",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "confusion_matrices",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "ID",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "54930c07-15f2-419d-8d49-60da63e90d8d",
       "rows": [
        [
         "0",
         "0",
         "3",
         "1000",
         "0.0001",
         "32.867549896240234",
         "0.51725",
         "0.4662",
         "0.2838",
         "[[552  44  26  38  21  28  11  63 167  36]\n [ 79 600  14  22  16  14  13  41 107 101]\n [113  32 345  73 119  92  85 106  36  14]\n [ 44  43  82 296  57 235  99 102  29  35]\n [ 80  38 151  66 366  65 106 126  38  10]\n [ 17  35  99 173  44 398  60  95  18  16]\n [ 33  50  92 119 109  84 460  54  14  11]\n [ 40  29  48  38  75  74  27 545  29  38]\n [132  68  12  19  15  37   4  24 653  42]\n [ 63 232   7  13   7  23  15  53 134 447]]",
         "3_1000_0.0001"
        ],
        [
         "1",
         "1",
         "5",
         "1000",
         "0.0001",
         "44.35795760154724",
         "0.50365",
         "0.4659",
         "0.1903",
         "[[541  83  37  23  57  25  14  46 111  49]\n [ 34 675  16  21  33  13  19  25  55 116]\n [116  35 231  43 247 142 108  60  18  15]\n [ 44  45  60 213 124 325 127  40  22  22]\n [ 70  39  75  32 523  86 113  77  21  10]\n [ 29  47  58  85 100 479  78  50  17  12]\n [ 25  51  46  57 184 130 497  18   8  10]\n [ 42  36  36  32 138  95  45 461  19  39]\n [129 113  12  17  41  33   3  19 568  71]\n [ 36 265   5  33  34  17  28  52  53 471]]",
         "5_1000_0.0001"
        ],
        [
         "2",
         "2",
         "2",
         "1000",
         "0.0001",
         "21.166707277297974",
         "0.52245",
         "0.4629",
         "0.1879",
         "[[587  52  43  32  32  12  19  45 115  49]\n [ 51 615  18  41  16  13  22  35  72 124]\n [119  27 321 122 132  89  97  67  19  22]\n [ 46  26  71 429  62 130 124  59  30  45]\n [ 74  35 163  98 359  59 115  96  25  22]\n [ 28  31  96 299  50 277  76  55  24  19]\n [ 24  35  91 166  94  64 478  41  16  17]\n [ 60  19  52  86  81  61  27 493  15  49]\n [163  88  10  52  18  13   5  23 567  67]\n [ 66 215  10  32  17  18  23  52  58 503]]",
         "2_1000_0.0001"
        ],
        [
         "3",
         "3",
         "2",
         "1000",
         "0.001",
         "20.380999088287354",
         "0.489125",
         "0.4611",
         "0.2809",
         "[[493  33  74  36  22  20  16  21 129 142]\n [ 51 527  12  21  23   6  17  18  50 282]\n [ 76  30 327 105 145  79 122  49  21  61]\n [ 22  27  77 361 105 147 139  30  30  84]\n [ 59  29 155  65 417  52 117  71  23  58]\n [ 12  23 102 221  76 293  96  50  32  50]\n [ 17  20  89 123 137  41 512  22  10  55]\n [ 44  19  61  78  96  46  33 417  23 126]\n [107  74  18  34  19  12  10   7 544 181]\n [ 29 123   8  20  19   7   9  21  38 720]]",
         "2_1000_0.001"
        ],
        [
         "4",
         "4",
         "3",
         "500",
         "0.0001",
         "11.186117172241211",
         "0.485825",
         "0.4604",
         "0.2647",
         "[[524  60  60  38  15  15  20  46 136  72]\n [ 40 591  26  31  19  11  34  37  52 166]\n [100  30 329  97 122  60 132  86  26  33]\n [ 39  33  95 326  67 158 159  72  21  52]\n [ 67  33 159  68 360  51 125 127  27  29]\n [ 25  30  93 193  53 324 105  83  24  25]\n [ 13  34 109 116  98  43 539  46   9  19]\n [ 46  26  54  59  88  58  42 486  21  63]\n [119 106  24  31  15  25   6  20 568  92]\n [ 51 205  13  19   9  17  24  48  51 557]]",
         "3_500_0.0001"
        ],
        [
         "5",
         "5",
         "8",
         "1000",
         "0.0001",
         "58.55350589752197",
         "0.487075",
         "0.4592",
         "0.2525",
         "[[531  77  39  52   6  39  12  59 105  66]\n [ 32 698   3  36   2  17   9  21  67 122]\n [ 85  49 258 137  91 163  99  94  24  15]\n [ 21  49  36 329  33 349  83  59  28  35]\n [ 60  48 165  76 295 116  99 135  32  20]\n [  7  46  54 161  27 508  53  60  20  19]\n [  5  71  76 164  97 153 414  26  10  10]\n [ 33  43  26  68  49 116  22 507  19  60]\n [154  94  10  28   6  56   3  20 562  73]\n [ 34 302   4  33   5  17  11  40  58 490]]",
         "8_1000_0.0001"
        ],
        [
         "6",
         "6",
         "2",
         "200",
         "0.001",
         "3.6978745460510254",
         "0.489",
         "0.4566",
         "0.2343",
         "[[552  65  45  33  30  24  20  28 133  56]\n [ 59 594   3  24  16   8  21  29  77 176]\n [103  40 271 101 180  87 131  45  25  32]\n [ 32  44  79 308  90 201 141  38  50  39]\n [ 77  36 116  71 425  62 129  72  31  27]\n [ 23  38  73 183  81 356  98  49  32  22]\n [ 15  47  53  99 145  65 535  21  23  23]\n [ 57  30  58  67  97  82  50 407  32  63]\n [155  80  23  19  20  24   4  14 589  78]\n [ 76 192   9  37  10  14  22  33  72 529]]",
         "2_200_0.001"
        ],
        [
         "7",
         "7",
         "1",
         "1000",
         "0.0001",
         "21.16045069694519",
         "0.5016",
         "0.4552",
         "0.313",
         "[[425  57  83  23  35  24  28  48 156 107]\n [ 43 524  19  18  18  11  25  39  72 238]\n [ 56  38 333  53 118 110 137  97  31  42]\n [ 17  50  77 262  78 211 153  79  34  61]\n [ 45  45 159  36 362  69 144 109  36  41]\n [ 15  44  85 145  71 365  86  80  31  33]\n [  7  48  77  84 104  83 536  45  20  22]\n [ 28  36  58  39  74  74  39 508  21  66]\n [ 72  58  34  18  24  22   7  17 608 146]\n [ 35 157  10  17  18  15  22  45  46 629]]",
         "1_1000_0.0001"
        ],
        [
         "8",
         "8",
         "2",
         "500",
         "0.001",
         "9.513328790664673",
         "0.490875",
         "0.4517",
         "0.262",
         "[[516  63  27  51  27  12  27  53 146  64]\n [ 80 575   9  13  24  11  31  36  44 184]\n [ 99  35 257  78 146  67 176 107  25  25]\n [ 41  26  71 215  60 178 255  96  27  53]\n [ 76  33  95  53 344  49 193 148  30  25]\n [ 25  32  67 138  48 297 202  89  22  35]\n [ 26  25  44  77 104  52 630  29  13  26]\n [ 40  22  34  31  76  54  81 534  17  54]\n [139  78  18  23  29  19  16  20 559 105]\n [ 47 176   6  17  14  11  32  50  51 590]]",
         "2_500_0.001"
        ],
        [
         "9",
         "9",
         "8",
         "500",
         "0.0001",
         "19.526729106903076",
         "0.470075",
         "0.4483",
         "0.2454",
         "[[484  64  51  34  20  25  14  45 207  42]\n [ 45 653  12  27  15  21  13  33  90  98]\n [109  35 316  87 130  97 107  90  39   5]\n [ 43  44  87 277  61 269 113  61  34  33]\n [ 68  42 198  50 358  72 111  96  37  14]\n [ 18  43  88 145  59 431  64  70  27  10]\n [ 21  50 113 111 130 129 425  27  12   8]\n [ 38  36  54  56  99  76  24 487  24  49]\n [ 96 111  12  27   9  32   5  21 653  40]\n [ 49 298  10  37   8  18  17  52 106 399]]",
         "8_500_0.0001"
        ],
        [
         "10",
         "10",
         "3",
         "500",
         "0.001",
         "10.914350271224976",
         "0.482275",
         "0.4475",
         "0.2467",
         "[[487  62  97  10  13  18  24  53 142  80]\n [ 54 557  11   6  14  13  28  36  50 238]\n [ 75  36 329  35  65  92 229 100  27  27]\n [ 24  39  93 158  42 232 242  97  36  59]\n [ 60  46 169  21 243  61 258 127  33  28]\n [ 14  41 101  99  24 346 173  98  31  28]\n [ 18  38  85  41  57  50 657  46  11  23]\n [ 35  25  66  23  57  64  82 522  20  49]\n [134  96  19   8  10  31  16  17 578  97]\n [ 63 165   9  15  12  14  30  50  38 598]]",
         "3_500_0.001"
        ],
        [
         "11",
         "11",
         "5",
         "500",
         "0.0001",
         "13.651635646820068",
         "0.475375",
         "0.4475",
         "0.2852",
         "[[403  43  30  31   3  12  18 102 252  92]\n [ 24 530   5  27   8   4  26  49  99 235]\n [ 83  33 235 111  69  56 175 169  50  34]\n [ 22  29  41 356  32 144 169 128  39  62]\n [ 51  29 123  62 260  51 191 193  48  38]\n [  8  35  59 225  28 269 132 131  38  30]\n [ 17  38  58 114  65  47 574  67  17  29]\n [ 24  23  23  50  42  35  62 576  30  78]\n [ 61  60  12  34   5  14   6  29 662 123]\n [ 22 161   5  18   5  11  22  65  75 610]]",
         "5_500_0.0001"
        ],
        [
         "12",
         "12",
         "2",
         "500",
         "0.0001",
         "9.9208345413208",
         "0.48465",
         "0.447",
         "0.2146",
         "[[608  59  32  20  30  29  31  53  92  32]\n [ 69 575  13  31  24  27  51  39  66 112]\n [124  32 234  82 100 133 187  88  20  15]\n [ 51  43  52 253  50 281 173  60  19  40]\n [ 81  25 107  45 322  86 228 116  22  14]\n [ 23  29  48 141  51 433 120  72  19  19]\n [ 27  48  67  90  69  90 574  33  10  18]\n [ 57  29  28  50  69  78  78 499  15  40]\n [204  89   5  20  20  45  15  32 510  66]\n [101 220   7  27  10  20  34  59  54 462]]",
         "2_500_0.0001"
        ],
        [
         "13",
         "13",
         "5",
         "1000",
         "0.001",
         "39.827409982681274",
         "0.465475",
         "0.4426",
         "0.2342",
         "[[474  62  39  20  27  31  11  42 232  48]\n [ 34 647   8  29  13   9   8  21 134 104]\n [103  47 217 109 132 127 124 101  40  15]\n [ 31  37  47 293  79 239 115  82  71  28]\n [ 70  53 114  69 368  58 126 116  46  26]\n [ 17  55  60 189  63 349  80  74  54  14]\n [ 22  34  54 175 131  64 464  30  38  14]\n [ 37  38  24  72  89  87  28 490  35  43]\n [117  71  10  19  12  22   6  13 684  52]\n [ 36 248   4  51   7  23   7  39 139 440]]",
         "5_1000_0.001"
        ],
        [
         "14",
         "14",
         "5",
         "500",
         "0.001",
         "13.571498155593872",
         "0.470525",
         "0.4426",
         "0.1999",
         "[[445  75  16  52  32  19  17  34 232  64]\n [ 38 614   3  38  21  12  16  31  87 147]\n [122  33 151 171 137  92 159  80  42  28]\n [ 47  23  18 421  78 194 117  49  32  43]\n [ 78  28  67 103 358  54 198  92  43  25]\n [ 32  24  27 288  52 343  78  56  29  26]\n [ 26  27  36 195 105  76 500  23  10  28]\n [ 66  20  21  86  99  76  43 433  28  71]\n [ 65 101   5  45  21  27   2  13 648  79]\n [ 35 238   4  37  14  18  16  29  90 513]]",
         "5_500_0.001"
        ],
        [
         "15",
         "15",
         "1",
         "500",
         "0.0001",
         "7.753991365432739",
         "0.472",
         "0.439",
         "0.2821",
         "[[537  59  38  49  29  18  12  45 139  60]\n [ 62 557  16  31  16  22  20  30  72 181]\n [100  44 258 138 139 100  86  89  39  22]\n [ 42  50  46 411  54 195  84  48  46  46]\n [ 70  48 109 112 358  83  99 100  41  26]\n [ 21  48  55 296  44 318  60  59  28  26]\n [ 20  55  79 188 101 102 399  42  23  17]\n [ 49  48  35  90  85  58  32 459  29  58]\n [174  66  16  34  18  26   6  18 540 108]\n [ 75 175  11  26  14  20  21  37  62 553]]",
         "1_500_0.0001"
        ],
        [
         "16",
         "16",
         "5",
         "200",
         "0.001",
         "3.8690147399902344",
         "0.453025",
         "0.4378",
         "0.2028",
         "[[597  49  82  11  11  36  10  33 119  38]\n [ 75 541  16   9  17  50  15  31  57 196]\n [121  29 345  38 142 157  85  65  17  16]\n [ 65  23 117 138  77 386  79  71  21  45]\n [100  28 186  32 381  95  85 104  16  19]\n [ 41  33 115  57  55 502  55  64  24   9]\n [ 30  31  90  63 192 169 389  36   9  17]\n [ 83  26  97  20  87 103  18 457  11  41]\n [214  70  16   4  14  58   4  15 537  74]\n [106 191  16  16   8  40  16  47  63 491]]",
         "5_200_0.001"
        ],
        [
         "17",
         "17",
         "8",
         "200",
         "0.001",
         "4.812864542007446",
         "0.4574",
         "0.4358",
         "0.2305",
         "[[556  52  44  34  15  15  23  82  98  67]\n [ 73 577   6  17  17  12  22  52  56 175]\n [138  28 271 101 120  83 153  85  19  17]\n [ 39  31  81 276  75 228 158  58  31  45]\n [ 74  33 199  54 304  62 163 124  17  16]\n [ 22  29  81 162  50 386 114  57  31  23]\n [ 15  34 102 123 101  71 531  17  14  18]\n [ 47  19  36  58 110  85  66 454  14  54]\n [195  88  12  24  15  27   4  35 503 103]\n [ 69 232   4  25  13  10  24  76  41 500]]",
         "8_200_0.001"
        ],
        [
         "18",
         "18",
         "3",
         "1000",
         "0.001",
         "32.89896249771118",
         "0.457875",
         "0.4328",
         "0.2422",
         "[[416  52  40  30  23  38   9  84 234  60]\n [ 19 509   7  34   9  18  13  56 126 216]\n [ 73  38 175 140 186 107  58 186  34  18]\n [ 32  36  36 377  63 203  59 139  41  36]\n [ 40  34  73  83 369  90  64 233  40  20]\n [ 15  27  41 272  44 344  33 138  23  18]\n [ 15  27  33 168 167 152 343  87  14  20]\n [ 23  16  24  59  54  85  17 594  30  41]\n [ 73  66  21  36   9  25   9  30 681  56]\n [ 20 149   7  24   9  24  22  74 145 520]]",
         "3_1000_0.001"
        ],
        [
         "19",
         "19",
         "3",
         "200",
         "0.001",
         "3.512172222137451",
         "0.46095",
         "0.4321",
         "0.2507",
         "[[438  72  53  37  11   5  24  45 200 101]\n [ 22 579   4  21   8   5  29  17  82 240]\n [ 82  54 333  84  47  50 196 102  35  32]\n [ 29  62 100 307  38 100 191 110  33  52]\n [ 48  51 203  61 157  36 279 127  44  40]\n [ 25  43 108 264  24 197 151  87  28  28]\n [ 17  48  98  99  32  41 588  57  17  29]\n [ 22  43  68  58  35  41  70 490  30  86]\n [ 75  78  17  44  11   1  14  19 639 108]\n [ 21 197  11  22   3  13  20  38  76 593]]",
         "3_200_0.001"
        ],
        [
         "20",
         "20",
         "1",
         "200",
         "0.001",
         "3.097592830657959",
         "0.46695",
         "0.4303",
         "0.1982",
         "[[591  56  40  27  15  10  45  42 110  50]\n [ 74 589  15  33  13   7  70  35  59 112]\n [108  29 285  84  77  63 234  71  26  38]\n [ 56  21  71 320  36 118 259  70  31  40]\n [ 93  27 131  90 182  43 337 101  27  15]\n [ 42  17  78 195  34 268 208  67  25  21]\n [ 43  22  56 115  47  62 620  34  12  15]\n [ 74  24  48  52  50  50 106 470  24  45]\n [155 104  13  30  11  10  30  13 546  94]\n [ 90 240   6  27  15  15  48  60  61 432]]",
         "1_200_0.001"
        ],
        [
         "21",
         "21",
         "3",
         "100",
         "0.001",
         "2.0264599323272705",
         "0.455275",
         "0.4276",
         "0.2695",
         "[[413  83  70  56  23  16  17  72 198  38]\n [ 22 616  20  51   9  14  26  41  75 133]\n [ 61  50 275 143  82  94 154 118  27  11]\n [ 13  39  71 382  34 230 107  71  45  30]\n [ 36  40 181  93 251  78 183 127  33  24]\n [ 14  37  84 264  28 335  70  88  22  13]\n [  6  36  98 185  55 119 474  34  11   8]\n [ 20  33  47 100  47  73  42 510  27  44]\n [ 80 125  37  36  12  26  11  27 597  55]\n [ 33 251  16  54   6  21  28  57 105 423]]",
         "3_100_0.001"
        ],
        [
         "22",
         "22",
         "5",
         "100",
         "0.001",
         "2.196690082550049",
         "0.447125",
         "0.4274",
         "0.1984",
         "[[507  44  52  16  34  17  18  27 229  42]\n [ 63 502   9  12  19  15  21  28 153 185]\n [107  25 307  55 201  61 127  44  56  32]\n [ 56  35  91 219 103 161 180  54  55  68]\n [ 84  26 159  31 411  35 153  66  55  26]\n [ 28  27 105 148  88 294 130  56  54  25]\n [ 25  28 104  61 149  43 527  27  26  36]\n [ 67  24  64  34 152  51  51 378  47  75]\n [128  52  14  10  14  28  15  12 682  51]\n [ 97 178   8  14  14  17  21  34 164 447]]",
         "5_100_0.001"
        ],
        [
         "23",
         "23",
         "8",
         "500",
         "0.001",
         "19.247365713119507",
         "0.4444",
         "0.427",
         "0.247",
         "[[437  31  27   5  31  54  26  53 240  82]\n [ 64 414   3  10  19  13  25  36 122 301]\n [ 93  23 148  24 126 232 184 115  42  28]\n [ 22  18  28  92  31 427 152 111  62  79]\n [ 61  19  91   7 257 136 194 190  45  46]\n [ 14  23  22  40  28 513 104 108  54  49]\n [ 11  21  39  52  92 120 557  75  15  44]\n [ 34  14  18  20  52 127  39 540  29  70]\n [108  28   4   2  12  33  12  15 683 109]\n [ 42 115   2   9   6  24  19  48 100 629]]",
         "8_500_0.001"
        ],
        [
         "24",
         "24",
         "2",
         "200",
         "0.0001",
         "3.6156575679779053",
         "0.44575",
         "0.4252",
         "0.2054",
         "[[492  53  50  25  22  22  38  38 183  63]\n [ 37 537  22  33  24  24  41  42  71 176]\n [100  32 256 111 156  62 166  66  38  28]\n [ 45  45  58 316  72 181 154  65  29  57]\n [ 63  29 132  76 333  46 174 118  39  36]\n [ 25  42  83 194  68 329 101  56  28  29]\n [ 30  41  65 116 128  75 499  32  14  26]\n [ 46  32  62  60  87  69  74 411  24  78]\n [124  90  18  39  19  23  10  23 567  93]\n [ 37 233  16  25  12  20  28  37  74 512]]",
         "2_200_0.0001"
        ],
        [
         "25",
         "25",
         "1",
         "100",
         "0.001",
         "1.852949619293213",
         "0.465325",
         "0.4241",
         "0.2306",
         "[[503  64  57  33  38  25  19  34 180  33]\n [ 61 536  25  41  17  11  13  33 157 113]\n [ 89  34 327 119  99  78 111  90  45  23]\n [ 29  22  92 375  56 169 112  61  64  42]\n [ 72  26 169 122 287  65 117 116  52  20]\n [ 22  25  92 257  41 298  87  68  48  17]\n [ 22  27 142 170  93  48 410  52  40  22]\n [ 50  31  67  88  78  59  46 434  31  59]\n [134  76  17  29  17  28   7  12 608  78]\n [ 71 218  12  35  15  12  29  45  94 463]]",
         "1_100_0.001"
        ],
        [
         "26",
         "26",
         "5",
         "200",
         "0.0001",
         "3.8732316493988037",
         "0.438675",
         "0.4234",
         "0.2318",
         "[[474  56  52  31   9  14  27  47 217  59]\n [ 34 533  13  31  18   9  35  41  95 198]\n [ 99  46 319  95 120  54 145  71  37  29]\n [ 35  51  89 319  61 131 158  73  46  59]\n [ 57  48 197  57 311  49 157  96  40  34]\n [ 27  48  99 219  55 269 123  57  36  22]\n [ 22  53 114 129  99  46 488  38  12  25]\n [ 51  51  60  67  97  56  53 412  31  65]\n [105  89  20  34   8  23   9  15 621  82]\n [ 49 217  12  25   9  10  30  37 117 488]]",
         "5_200_0.0001"
        ],
        [
         "27",
         "27",
         "2",
         "100",
         "0.001",
         "2.1211600303649902",
         "0.458175",
         "0.4219",
         "0.2191",
         "[[498  51  49  24  22  55  20  48 164  55]\n [ 63 561  15  20   8  24  30  39  75 172]\n [ 82  45 307  76  60 124 170  84  44  23]\n [ 33  50 106 222  43 250 171  74  41  32]\n [ 63  43 200  55 192  84 218 123  46  22]\n [ 16  47  93 152  39 354 122  86  29  17]\n [ 19  40 107  88  50 101 546  48  13  14]\n [ 47  37  69  51  51  80  62 458  34  54]\n [119  84  16  23  12  56   7  16 596  77]\n [ 60 181  14  39   7  31  27  42 108 485]]",
         "2_100_0.001"
        ],
        [
         "28",
         "28",
         "1",
         "50",
         "0.001",
         "1.131866455078125",
         "0.44725",
         "0.4211",
         "0.3099",
         "[[404  61 103  43  26  26  25  51 141 106]\n [ 67 527  27  31   5  23  25  48  58 196]\n [ 59  33 334  66 115 116 166  77  20  29]\n [ 29  38 114 283  43 238 146  42  37  52]\n [ 52  51 137  73 290  89 202  93  26  33]\n [ 13  35  86 184  51 374 104  61  27  20]\n [ 13  45  79 112  77 104 519  41  16  20]\n [ 38  43  64  67  78  69  64 429  20  71]\n [ 92  97  60  34  12  31  12  19 535 114]\n [ 54 202  30  23  10  20  25  53  61 516]]",
         "1_50_0.001"
        ],
        [
         "29",
         "29",
         "8",
         "100",
         "0.001",
         "2.6276776790618896",
         "0.439525",
         "0.4201",
         "0.3043",
         "[[425  72  27  45  34  11  31  48 226  67]\n [ 23 610   4  47  22   5  21  19  97 159]\n [100  32 188 164 155  31 188  77  52  28]\n [ 17  38  56 478  64  88 145  50  38  48]\n [ 71  37 115 101 354  32 198  92  30  16]\n [ 11  40  57 405  53 171 110  53  34  21]\n [ 10  37  57 207 118  19 521  24  15  18]\n [ 47  29  29 106 148  38  60 393  30  63]\n [ 92 125  12  62  12   5   8  16 580  94]\n [ 46 272   4  42  10   3  22  31  83 481]]",
         "8_100_0.001"
        ],
        [
         "30",
         "30",
         "3",
         "200",
         "0.0001",
         "3.5419442653656006",
         "0.44475",
         "0.4175",
         "0.246",
         "[[451  41 105  42  13  12  15  68 183  56]\n [ 41 544  24  27  17  14  19  73  99 149]\n [ 80  31 349 113  96  45 120 116  42  23]\n [ 33  57 100 331  40 148 133 102  33  45]\n [ 64  29 221  74 238  38 144 176  32  30]\n [ 15  44 100 226  36 278 100 107  34  15]\n [ 20  56 115 137  99  45 451  62   8  33]\n [ 32  37  74  65  73  44  50 481  30  57]\n [113  78  27  29   9  26   3  35 604  82]\n [ 49 244  15  31  11   9  14  64 109 448]]",
         "3_200_0.0001"
        ],
        [
         "31",
         "31",
         "2",
         "50",
         "0.001",
         "1.3103947639465332",
         "0.433525",
         "0.4153",
         "0.2731",
         "[[481  62  70  27  29  40  15  44 138  80]\n [ 39 603  14  27  30  23  20  33  64 154]\n [ 86  61 287  94 132 108 120  65  35  27]\n [ 32  59  90 317  83 166 110  72  42  51]\n [ 45  58 162  72 379  82 113  78  31  26]\n [ 19  48 100 243  69 285  66  77  30  18]\n [ 16  60  81 167 148  70 402  41  13  28]\n [ 35  43  76  75 106  70  36 409  20  73]\n [134  93  30  32  15  39   7  20 518 118]\n [ 38 257   9  41  20  18  23  31  85 472]]",
         "2_50_0.001"
        ],
        [
         "32",
         "32",
         "1",
         "200",
         "0.0001",
         "3.2105400562286377",
         "0.4384",
         "0.415",
         "0.2172",
         "[[509  55  47  39  18  36  19  46 149  68]\n [ 62 539  12  49  21  29  25  42  72 156]\n [ 99  25 236 150 106 123 115  91  37  33]\n [ 36  40  54 365  49 242  89  66  33  48]\n [ 64  30 114 114 290  89 118 151  39  37]\n [ 19  29  66 232  54 367  59  70  38  21]\n [ 17  37  55 198  98 111 410  42  21  37]\n [ 38  41  47  79  83  91  41 423  35  65]\n [154  90  28  24  10  43  10  30 525  92]\n [ 51 208  10  52  12  17  35  46  77 486]]",
         "1_200_0.0001"
        ],
        [
         "33",
         "33",
         "8",
         "1000",
         "0.001",
         "62.88999271392822",
         "0.42795",
         "0.4135",
         "0.3154",
         "[[481  42  55  63  19   9  20  84 159  54]\n [ 48 535   9  77  11   5   9  57 102 154]\n [111  19 188 241 170  19 150  85  19  13]\n [ 28  27  43 554  58 101 133  44  19  15]\n [ 64  20 119 168 300  11 186 150  17  11]\n [ 14  19  63 455  39 196  90  55  14  10]\n [ 22  28  33 247 149  10 485  37   5  10]\n [ 30  18  60 190  55  22  51 477  15  25]\n [126  54  27  51  22  27   7  22 571  99]\n [ 40 301   8 105  12   3  20  87  70 348]]",
         "8_1000_0.001"
        ],
        [
         "34",
         "34",
         "8",
         "200",
         "0.0001",
         "4.828750848770142",
         "0.42725",
         "0.4128",
         "0.2151",
         "[[479  33  36  22  12  26  24  45 234  75]\n [ 38 410  17  36  19  15  35  44 138 255]\n [136  25 277  83 137  88 125  77  46  21]\n [ 46  35  90 240  47 238 143  79  50  54]\n [ 83  34 171  45 290  83 140 136  36  28]\n [ 31  24  94 135  49 391  85  77  40  29]\n [ 34  43 108  85 122  99 450  47  12  26]\n [ 60  23  59  39  93  97  71 392  37  72]\n [116  60  12  26  11  25   5  17 624 110]\n [ 49 149   8  29   4  15  28  43  94 575]]",
         "8_200_0.0001"
        ],
        [
         "35",
         "35",
         "1",
         "500",
         "0.001",
         "7.684340000152588",
         "0.453225",
         "0.408",
         "0.1272",
         "[[594  84  36  13  46  25  21  52  45  70]\n [ 59 601  15   6  22  17  22  86  35 144]\n [134  24 213  41 169 131 110 149  17  27]\n [ 85  40  73 212 117 148 147 159  15  26]\n [ 78  35  77  32 388  83 125 191  12  25]\n [ 44  26  97 155  88 268 112 132  14  19]\n [ 40  26  37  79 122  72 499 131   6  14]\n [ 69  32  25  28  59  76  36 550  11  57]\n [230 161   9  17  51  40   7  27 318 146]\n [ 82 265   6  17  15  30  29  95  18 437]]",
         "1_500_0.001"
        ],
        [
         "36",
         "36",
         "5",
         "50",
         "0.001",
         "1.3079745769500732",
         "0.422425",
         "0.4059",
         "0.184",
         "[[474  53  76  21  10  25  19  66 192  50]\n [ 53 483  22  33   5  20  21  43  75 252]\n [105  31 374  52  51 131 115 107  23  26]\n [ 57  36 110 244  39 247 120  97  29  43]\n [ 74  35 283  50 136  77 154 183  30  24]\n [ 37  42 121 163  24 340  82  85  28  33]\n [ 21  41 169  94  42 115 445  61  11  27]\n [ 44  30  91  47  47  73  52 477  32  50]\n [137 106  27  17   3  31   8  24 559  94]\n [ 53 157  15  23   1  20  29  65 104 527]]",
         "5_50_0.001"
        ],
        [
         "37",
         "37",
         "1",
         "1000",
         "0.001",
         "15.029110670089722",
         "0.450275",
         "0.4039",
         "0.1949",
         "[[454  36  51  77  73  52   6  36  51 150]\n [100 434  29  15  65  56  18  33  47 210]\n [ 75   9 277  87 195 208  59  61  12  32]\n [ 19  11  75 268 129 305  73  61  19  62]\n [ 47  14  95 110 439 135  53  93  14  46]\n [ 19  16  65 215 109 407  29  50   7  38]\n [  8  19  77 113 197 164 355  37   7  49]\n [ 44   9  36  59 112 147   8 441  16  71]\n [213  60  11  50  36  52   5  19 413 147]\n [ 63 116  21  19  52  82   9  41  40 551]]",
         "1_1000_0.001"
        ],
        [
         "38",
         "38",
         "3",
         "50",
         "0.001",
         "1.2957677841186523",
         "0.42495",
         "0.4012",
         "0.2304",
         "[[374  55  82  37  17  47  18  53 249  54]\n [ 44 533  14  31  15  13  25  49 131 152]\n [ 75  39 285  79  81 137 139 124  43  13]\n [ 26  65  73 283  45 241 121  93  35  40]\n [ 74  38 215  79 235  65 129 150  37  24]\n [ 16  45  80 204  30 352  90  89  33  16]\n [ 17  67 101 111 103 114 419  59  13  22]\n [ 46  35  61  62  43  73  45 482  40  56]\n [105  58  20  48  15  30   6  26 638  60]\n [ 36 227   6  31  17  20  25  62 159 411]]",
         "3_50_0.001"
        ],
        [
         "39",
         "39",
         "8",
         "50",
         "0.001",
         "1.6415090560913086",
         "0.40975",
         "0.4009",
         "0.2258",
         "[[369  33  77  19  17  54  23  66 282  46]\n [ 23 487  12  31   6  34  25  48 146 195]\n [ 70  14 300  35 124 161 170  97  33  11]\n [ 29  35 100 117  33 385 159 101  35  28]\n [ 54  22 204  24 248 101 192 142  38  21]\n [ 17  30  81  82  38 443 127  80  39  18]\n [  6  34 130  48  82 139 520  42  16   9]\n [ 35  22 107  27  78  92  62 439  42  39]\n [103  48  22  11   4  62   5  25 652  74]\n [ 45 172  24  30   4  29  21  60 175 434]]",
         "8_50_0.001"
        ],
        [
         "40",
         "40",
         "1",
         "100",
         "0.0001",
         "1.807054042816162",
         "0.41565",
         "0.398",
         "0.2591",
         "[[451  49  68  55  35  26  13  60 189  40]\n [ 60 502  35  45  27  16  28  54  84 156]\n [ 81  30 298 159 125  59 119  89  34  21]\n [ 41  34  87 386  75 135 114  67  33  50]\n [ 58  31 150  88 319  60 168 106  34  32]\n [ 27  33  91 313  67 239  64  80  29  12]\n [ 25  31  92 188 136  74 399  48  14  19]\n [ 41  33  51  86  92  70  49 439  25  57]\n [133  99  25  56  27  23   4  33 525  81]\n [ 62 255  17  32  20  31  23  55  77 422]]",
         "1_100_0.0001"
        ],
        [
         "41",
         "41",
         "2",
         "100",
         "0.0001",
         "2.139780044555664",
         "0.412175",
         "0.3972",
         "0.2125",
         "[[377  62  69  32  12  26  25  51 270  62]\n [ 33 469  22  42  19  25  53  45 111 188]\n [ 74  34 277 117  96  83 159  89  47  39]\n [ 31  37  87 318  32 203 137  64  38  75]\n [ 50  38 151  84 234  61 200 133  45  50]\n [ 16  44  82 225  31 324  99  68  32  34]\n [ 13  45 100 145  73  88 466  45  13  38]\n [ 24  36  50  94  62  82  93 387  38  77]\n [ 75  88  25  26  11  31   9  18 631  92]\n [ 29 171  14  41   8  26  35  48 133 489]]",
         "2_100_0.0001"
        ],
        [
         "42",
         "42",
         "3",
         "100",
         "0.0001",
         "2.014181137084961",
         "0.408775",
         "0.3905",
         "0.2456",
         "[[430  73  49  23   7  30  32  59 219  64]\n [ 41 471  10  21  21  37  41  42 101 222]\n [ 95  36 231  82  89  91 198 113  37  43]\n [ 41  54  69 206  45 222 166 115  33  71]\n [ 60  46 136  59 208  82 210 172  34  39]\n [ 32  44  69 149  31 361  99 104  32  34]\n [ 28  56  63  89  78  95 507  65   6  39]\n [ 38  54  42  39  68  90  95 413  39  65]\n [112 101  17  24   9  37   8  28 562 108]\n [ 37 200  11  14   6  28  31  43 108 516]]",
         "3_100_0.0001"
        ],
        [
         "43",
         "43",
         "8",
         "100",
         "0.0001",
         "2.6161463260650635",
         "0.381875",
         "0.3823",
         "0.2389",
         "[[435  46  17  34   9  28  40  44 269  64]\n [ 35 390   4  45  25  17  51  33 145 262]\n [130  26 102  92 107  75 283 126  51  23]\n [ 55  43  28 217  52 212 233  78  35  69]\n [ 59  43  74  68 228  77 303 110  50  34]\n [ 27  31  31 115  44 347 206  79  46  29]\n [ 33  50  46  77  80  64 599  35  16  26]\n [ 43  46  25  49 116  74 129 340  40  81]\n [124  78   7  28   2  37   9  21 604  96]\n [ 42 160   4  22   9  10  45  29 112 561]]",
         "8_100_0.0001"
        ],
        [
         "44",
         "44",
         "5",
         "100",
         "0.0001",
         "2.185671091079712",
         "0.387975",
         "0.3817",
         "0.2431",
         "[[407  70  37  13  17  29  38  48 253  74]\n [ 37 449  12  28  37  18  37  32 100 257]\n [106  45 198  49 170  99 150 119  44  35]\n [ 33  73  54 200  88 221 127 106  51  69]\n [ 57  50  97  33 365  87 144 130  46  37]\n [ 26  62  40 159  73 343  93 101  36  22]\n [ 21  62  53 103 221  71 366  75  11  43]\n [ 32  56  35  49 153  70  67 368  38  75]\n [ 87  85   8  12  17  36   2  29 593 137]\n [ 42 194   5  24  17  11  26  45 102 528]]",
         "5_100_0.0001"
        ],
        [
         "45",
         "45",
         "3",
         "1000",
         "1e-05",
         "27.528873920440674",
         "0.392425",
         "0.3799",
         "0.2005",
         "[[445  69  39  41   8  17  20  60 213  74]\n [ 35 422  21  55  19  23  56  59  85 232]\n [127  50 192 128 120  57 161 119  30  31]\n [ 39  49  64 299  74 173 129 106  31  58]\n [ 57  44 110  80 290  71 164 150  35  45]\n [ 32  33  52 212  51 310 106 105  27  27]\n [ 27  54  67 129 106  78 434  83  10  38]\n [ 36  49  49  78  91  73  75 382  29  81]\n [121  92  18  38  14  35   8  33 527 120]\n [ 46 188  11  52   8  15  32  57  87 498]]",
         "3_1000_1e-05"
        ],
        [
         "46",
         "46",
         "2",
         "1000",
         "1e-05",
         "21.58355689048767",
         "0.387275",
         "0.3798",
         "0.2027",
         "[[432  65  31  38  17  24  27  40 219  93]\n [ 40 420  17  39  27  32  45  49  81 257]\n [101  53 226  83 109  92 172  86  53  40]\n [ 42  60  79 259  74 170 167  68  31  72]\n [ 62  39 130  70 235  80 205 137  33  55]\n [ 34  46  67 189  49 306 113  77  33  41]\n [ 28  63  77 116  88  60 475  55  11  53]\n [ 32  50  62  66  69  81  93 358  35  97]\n [115  88  19  38  15  36   4  24 546 121]\n [ 49 158  18  23  12  17  31  44 101 541]]",
         "2_1000_1e-05"
        ],
        [
         "47",
         "47",
         "1",
         "50",
         "0.0001",
         "1.1173317432403564",
         "0.39085",
         "0.3777",
         "0.2399",
         "[[425  65  47  30  14  31  29  59 207  79]\n [ 47 463  42  30  35  23  46  40  96 185]\n [102  40 216  81 128  83 172  99  54  40]\n [ 42  61  74 215  71 223 177  66  40  53]\n [ 62  43 146  56 306  83 167 110  26  47]\n [ 19  46  79 147  55 357 121  70  37  24]\n [ 28  60  83  92 102 115 463  39  13  31]\n [ 38  40  74  53 111  76  69 373  43  66]\n [130  94  18  19  10  54  18  24 500 139]\n [ 49 191  22  27  20  17  46  60 103 459]]",
         "1_50_0.0001"
        ],
        [
         "48",
         "48",
         "5",
         "1000",
         "1e-05",
         "47.565510749816895",
         "0.384875",
         "0.3731",
         "0.2126",
         "[[443  81  43  21  13  22  23  47 208  85]\n [ 33 474   7  34  36  16  41  36  86 244]\n [104  65 190  86 156  63 138 134  38  41]\n [ 37  91  65 230  95 178 118 118  22  68]\n [ 60  73 107  61 309  73 142 144  29  48]\n [ 31  73  51 177  62 308  92 102  29  30]\n [ 24  94  59 119 123  80 386  95  10  36]\n [ 48  72  37  60 122  61  70 351  22 100]\n [123  99  12  40   9  30   3  23 528 139]\n [ 49 227   6  19  14  11  30  46  80 512]]",
         "5_1000_1e-05"
        ],
        [
         "49",
         "49",
         "8",
         "1000",
         "1e-05",
         "58.3690505027771",
         "0.37895",
         "0.3731",
         "0.1901",
         "[[517  92  32  14   8  30  29  64 158  42]\n [ 56 556  10  12  19  24  36  61  70 163]\n [129  61 148  44 179 101 148 164  21  20]\n [ 46  77  62  97  68 295 145 167  20  45]\n [ 78  67  83  27 306 111 154 181  19  20]\n [ 35  69  28  65  67 426 104 129  19  13]\n [ 21  98  52  35 147 114 432 108   5  14]\n [ 39  81  30  21 111 122  79 389  23  48]\n [202 132  11   8   6  55   4  37 456  95]\n [ 59 314   9  11   5  21  29  63  79 404]]",
         "8_1000_1e-05"
        ]
       ],
       "shape": {
        "columns": 10,
        "rows": 75
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>hidden_layers</th>\n",
       "      <th>n_neurons</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>train_time</th>\n",
       "      <th>train_score</th>\n",
       "      <th>val_score</th>\n",
       "      <th>test_score</th>\n",
       "      <th>confusion_matrices</th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>32.867550</td>\n",
       "      <td>0.517250</td>\n",
       "      <td>0.4662</td>\n",
       "      <td>0.2838</td>\n",
       "      <td>[[552, 44, 26, 38, 21, 28, 11, 63, 167, 36], [...</td>\n",
       "      <td>3_1000_0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>44.357958</td>\n",
       "      <td>0.503650</td>\n",
       "      <td>0.4659</td>\n",
       "      <td>0.1903</td>\n",
       "      <td>[[541, 83, 37, 23, 57, 25, 14, 46, 111, 49], [...</td>\n",
       "      <td>5_1000_0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>21.166707</td>\n",
       "      <td>0.522450</td>\n",
       "      <td>0.4629</td>\n",
       "      <td>0.1879</td>\n",
       "      <td>[[587, 52, 43, 32, 32, 12, 19, 45, 115, 49], [...</td>\n",
       "      <td>2_1000_0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>20.380999</td>\n",
       "      <td>0.489125</td>\n",
       "      <td>0.4611</td>\n",
       "      <td>0.2809</td>\n",
       "      <td>[[493, 33, 74, 36, 22, 20, 16, 21, 129, 142], ...</td>\n",
       "      <td>2_1000_0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>500</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>11.186117</td>\n",
       "      <td>0.485825</td>\n",
       "      <td>0.4604</td>\n",
       "      <td>0.2647</td>\n",
       "      <td>[[524, 60, 60, 38, 15, 15, 20, 46, 136, 72], [...</td>\n",
       "      <td>3_500_0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>70</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>1.335903</td>\n",
       "      <td>0.207000</td>\n",
       "      <td>0.2055</td>\n",
       "      <td>0.1676</td>\n",
       "      <td>[[485, 136, 122, 0, 22, 9, 16, 5, 164, 27], [1...</td>\n",
       "      <td>2_50_1e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>71</td>\n",
       "      <td>8</td>\n",
       "      <td>100</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>2.594995</td>\n",
       "      <td>0.159600</td>\n",
       "      <td>0.1583</td>\n",
       "      <td>0.1085</td>\n",
       "      <td>[[237, 2, 164, 39, 0, 496, 0, 0, 0, 48], [83, ...</td>\n",
       "      <td>8_100_1e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>72</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>1.295890</td>\n",
       "      <td>0.154225</td>\n",
       "      <td>0.1503</td>\n",
       "      <td>0.1301</td>\n",
       "      <td>[[234, 10, 136, 6, 6, 218, 1, 276, 90, 9], [36...</td>\n",
       "      <td>3_50_1e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>73</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>1.292592</td>\n",
       "      <td>0.143000</td>\n",
       "      <td>0.1422</td>\n",
       "      <td>0.1033</td>\n",
       "      <td>[[390, 45, 150, 14, 0, 167, 0, 0, 219, 1], [87...</td>\n",
       "      <td>5_50_1e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>74</td>\n",
       "      <td>8</td>\n",
       "      <td>50</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>1.537595</td>\n",
       "      <td>0.100700</td>\n",
       "      <td>0.0990</td>\n",
       "      <td>0.0998</td>\n",
       "      <td>[[984, 0, 0, 0, 0, 0, 2, 0, 0, 0], [1004, 0, 0...</td>\n",
       "      <td>8_50_1e-05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    index  hidden_layers  n_neurons  learning_rate  train_time  train_score  \\\n",
       "0       0              3       1000        0.00010   32.867550     0.517250   \n",
       "1       1              5       1000        0.00010   44.357958     0.503650   \n",
       "2       2              2       1000        0.00010   21.166707     0.522450   \n",
       "3       3              2       1000        0.00100   20.380999     0.489125   \n",
       "4       4              3        500        0.00010   11.186117     0.485825   \n",
       "..    ...            ...        ...            ...         ...          ...   \n",
       "70     70              2         50        0.00001    1.335903     0.207000   \n",
       "71     71              8        100        0.00001    2.594995     0.159600   \n",
       "72     72              3         50        0.00001    1.295890     0.154225   \n",
       "73     73              5         50        0.00001    1.292592     0.143000   \n",
       "74     74              8         50        0.00001    1.537595     0.100700   \n",
       "\n",
       "    val_score  test_score                                 confusion_matrices  \\\n",
       "0      0.4662      0.2838  [[552, 44, 26, 38, 21, 28, 11, 63, 167, 36], [...   \n",
       "1      0.4659      0.1903  [[541, 83, 37, 23, 57, 25, 14, 46, 111, 49], [...   \n",
       "2      0.4629      0.1879  [[587, 52, 43, 32, 32, 12, 19, 45, 115, 49], [...   \n",
       "3      0.4611      0.2809  [[493, 33, 74, 36, 22, 20, 16, 21, 129, 142], ...   \n",
       "4      0.4604      0.2647  [[524, 60, 60, 38, 15, 15, 20, 46, 136, 72], [...   \n",
       "..        ...         ...                                                ...   \n",
       "70     0.2055      0.1676  [[485, 136, 122, 0, 22, 9, 16, 5, 164, 27], [1...   \n",
       "71     0.1583      0.1085  [[237, 2, 164, 39, 0, 496, 0, 0, 0, 48], [83, ...   \n",
       "72     0.1503      0.1301  [[234, 10, 136, 6, 6, 218, 1, 276, 90, 9], [36...   \n",
       "73     0.1422      0.1033  [[390, 45, 150, 14, 0, 167, 0, 0, 219, 1], [87...   \n",
       "74     0.0990      0.0998  [[984, 0, 0, 0, 0, 0, 2, 0, 0, 0], [1004, 0, 0...   \n",
       "\n",
       "               ID  \n",
       "0   3_1000_0.0001  \n",
       "1   5_1000_0.0001  \n",
       "2   2_1000_0.0001  \n",
       "3    2_1000_0.001  \n",
       "4    3_500_0.0001  \n",
       "..            ...  \n",
       "70     2_50_1e-05  \n",
       "71    8_100_1e-05  \n",
       "72     3_50_1e-05  \n",
       "73     5_50_1e-05  \n",
       "74     8_50_1e-05  \n",
       "\n",
       "[75 rows x 10 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "configurations_df = configurations_df.sort_values(by='val_score', ascending=False).reset_index(drop=True).reset_index()\n",
    "configurations_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "n_neurons",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "val_score",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "test_score",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "43f2608a-7c13-4614-9bba-f1866356c909",
       "rows": [
        [
         "1000",
         "0.42200666666666664",
         "0.23334"
        ],
        [
         "500",
         "0.40515333333333337",
         "0.21220000000000003"
        ],
        [
         "200",
         "0.37675333333333333",
         "0.1944533333333333"
        ],
        [
         "100",
         "0.34563333333333335",
         "0.20448666666666665"
        ],
        [
         "50",
         "0.30734666666666666",
         "0.19365333333333332"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>val_score</th>\n",
       "      <th>test_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_neurons</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>0.422007</td>\n",
       "      <td>0.233340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>0.405153</td>\n",
       "      <td>0.212200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>0.376753</td>\n",
       "      <td>0.194453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.345633</td>\n",
       "      <td>0.204487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.307347</td>\n",
       "      <td>0.193653</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           val_score  test_score\n",
       "n_neurons                       \n",
       "1000        0.422007    0.233340\n",
       "500         0.405153    0.212200\n",
       "200         0.376753    0.194453\n",
       "100         0.345633    0.204487\n",
       "50          0.307347    0.193653"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "configurations_df[['n_neurons', 'val_score', 'test_score']].groupby('n_neurons').mean().sort_values(by='val_score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "previous_results = pd.read_excel(\"Resultados por redes neuronales.xlsx\")\n",
    "previous_results['ID'] = previous_results['hidden_layers'].astype(str) + '_' + previous_results['n_neurons'].astype(str) + '_' + previous_results['learning_rate'].astype(str)\n",
    "previous_results = previous_results.sort_values(by='val_score', ascending=False).reset_index(drop=True).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "hidden_layers",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "n_neurons",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "learning_rate",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "train_time",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "train_score",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "val_score",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "test_score",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "confusion_matrices",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "val_accuracy_over_epochs",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "ID",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "4d2329f0-4cf8-49f9-b617-137cf7f84e61",
       "rows": [
        [
         "0",
         "0",
         "2",
         "1000",
         "0.0001",
         "736.9606878757477",
         "1.0",
         "0.4878",
         "0.4862",
         "[[197  36  14  29  13  10  41  56  43  59]\n [ 47 279  68  18  28  20  19  10   5  22]\n [  9  42 338   6  20  27  12  14  14  12]\n [ 35  12   7 261  19  13  39  33  10  57]\n [ 16  19  42  24 287  67  12  13  22  16]\n [ 11  26  36  13  82 297  16   8  11  13]\n [ 49   8  20  27  20  18 165  90  65  38]\n [ 33  10   6  31  10   9 107 196  49  40]\n [ 42   8   4  14  11  17  46  32 241  53]\n [ 64  31  13  51  13  10  33  32  46 223]]",
         "[0.4156, 0.4394, 0.4518, 0.4658, 0.4708, 0.475, 0.4778, 0.477, 0.4774, 0.4814, 0.4826, 0.4858, 0.4866, 0.4932, 0.4842, 0.4802, 0.4792, 0.486, 0.4904, 0.4896, 0.4864, 0.4848, 0.4752, 0.4848, 0.4876, 0.4848, 0.477, 0.4818, 0.4848, 0.482, 0.4846, 0.49, 0.4816, 0.4788, 0.482, 0.4856, 0.4876, 0.4886, 0.4866, 0.491, 0.4866, 0.4846, 0.4884, 0.4888, 0.4878, 0.4844, 0.4864, 0.487, 0.4834, 0.4858, 0.485, 0.4302, 0.4564, 0.4752, 0.4818, 0.49, 0.4932, 0.4928, 0.4944, 0.4918, 0.4968, 0.4934, 0.4924, 0.4884, 0.4916, 0.4928, 0.4918, 0.4902, 0.49, 0.4906, 0.4892, 0.489, 0.489, 0.4892, 0.4852, 0.4864, 0.489, 0.4878, 0.4864, 0.4886, 0.49, 0.4872, 0.4892, 0.491, 0.4896, 0.4876, 0.4874, 0.4892, 0.4858, 0.489, 0.4872, 0.486, 0.4872, 0.489, 0.4858, 0.4876, 0.486, 0.4872, 0.4868, 0.4848, 0.4866, 0.4854, 0.4858, 0.4874, 0.4874, 0.4856, 0.486, 0.4868, 0.4862, 0.4848, 0.4878]",
         "2_1000_0.0001"
        ],
        [
         "1",
         "1",
         "1",
         "1000",
         "1e-05",
         "1119.730063438416",
         "0.9838666666666667",
         "0.4822",
         "0.486",
         "[[181  41  14  30  13  15  43  53  41  67]\n [ 39 262  78  20  35  20  18  16   8  20]\n [ 12  44 335   9  25  23  13  11  12  10]\n [ 33  17   5 261  25   9  31  35  14  56]\n [ 15  23  30  31 277  87  15  11  17  12]\n [ 13  27  40  11  84 289  19   9   7  14]\n [ 41  14  19  35  15  23 159  93  65  36]\n [ 32  14   8  27  12  11 119 184  49  35]\n [ 28   9   2  13  12  14  50  30 255  55]\n [ 54  24  21  67  16   7  39  32  39 217]]",
         "[0.2848, 0.3324, 0.3556, 0.3758, 0.3894, 0.3996, 0.4092, 0.4134, 0.4226, 0.4256, 0.4304, 0.4346, 0.4404, 0.438, 0.4432, 0.4444, 0.4456, 0.4472, 0.4472, 0.4502, 0.451, 0.4488, 0.4516, 0.452, 0.4542, 0.4522, 0.4574, 0.4572, 0.4578, 0.4594, 0.4582, 0.4572, 0.4626, 0.46, 0.462, 0.4644, 0.4668, 0.463, 0.4662, 0.4672, 0.4642, 0.469, 0.4636, 0.4682, 0.466, 0.4674, 0.4696, 0.4708, 0.4704, 0.4704, 0.4694, 0.4734, 0.4716, 0.4728, 0.4736, 0.4736, 0.4738, 0.4748, 0.4716, 0.4746, 0.4732, 0.4754, 0.4754, 0.4718, 0.4768, 0.4768, 0.4762, 0.4736, 0.4758, 0.4758, 0.4786, 0.4748, 0.4748, 0.4736, 0.4756, 0.473, 0.4742, 0.4754, 0.4774, 0.4754, 0.4776, 0.477, 0.4764, 0.4756, 0.4776, 0.4756, 0.4744, 0.4762, 0.4744, 0.476, 0.4784, 0.4748, 0.475, 0.4782, 0.4744, 0.477, 0.4766, 0.478, 0.4764, 0.4746, 0.4772, 0.4762, 0.4748, 0.478, 0.4778, 0.4772, 0.4744, 0.4786, 0.4784, 0.4764, 0.4784, 0.4762, 0.4808, 0.4782, 0.481, 0.4782, 0.4774, 0.4792, 0.4798, 0.4822, 0.4786, 0.4812, 0.4816, 0.4772, 0.4782, 0.4796, 0.4834, 0.4806, 0.4808, 0.4808, 0.4828, 0.478, 0.481, 0.4802, 0.4816, 0.4806, 0.4798, 0.4802, 0.483, 0.48, 0.4814, 0.4822, 0.48, 0.4818, 0.4804, 0.4828, 0.4796, 0.4786, 0.4808, 0.4836, 0.4806, 0.4802, 0.4796, 0.4788, 0.4798, 0.4796, 0.4836, 0.4828, 0.4796, 0.4804, 0.4812, 0.4814, 0.4818, 0.4774, 0.4818, 0.4806, 0.4802, 0.4806, 0.4808, 0.4798, 0.4796, 0.4834, 0.4806, 0.4788, 0.484, 0.4792, 0.4792, 0.4818, 0.48, 0.48, 0.4816, 0.4826, 0.482, 0.4818, 0.4782, 0.4802, 0.479, 0.478, 0.4806, 0.4824, 0.4824, 0.48, 0.4782, 0.4802, 0.4802, 0.4806, 0.482, 0.4812, 0.4816, 0.4808, 0.4772, 0.4794, 0.48, 0.4782, 0.4804, 0.4814, 0.4776, 0.481, 0.4816, 0.4798, 0.4796, 0.4812, 0.48, 0.4816, 0.4794, 0.4822, 0.4794, 0.4796, 0.479, 0.4762, 0.4798, 0.4766, 0.4792, 0.4806, 0.4822]",
         "1_1000_1e-05"
        ],
        [
         "2",
         "2",
         "2",
         "1000",
         "1e-05",
         "824.7802395820618",
         "0.9910666666666667",
         "0.4812",
         "0.4762",
         "[[179  39  13  30  18  19  41  52  55  52]\n [ 48 268  67  16  36  23  15  14  14  15]\n [ 11  49 323  10  21  36  14  10   8  12]\n [ 34  16   8 262  21   9  28  39  20  49]\n [ 12  20  40  28 261  99  18  14  13  13]\n [  8  23  36  13  71 315  16   5  13  13]\n [ 40  15  21  25  21  20 161  98  73  26]\n [ 30   7   8  32   9  13 118 177  58  39]\n [ 30  10   3   9  12  18  46  25 271  44]\n [ 68  35  14  42  15  10  38  29  57 208]]",
         "[0.3122, 0.353, 0.3866, 0.4032, 0.4154, 0.4216, 0.429, 0.4288, 0.4352, 0.4428, 0.4424, 0.4442, 0.4478, 0.4558, 0.4528, 0.4552, 0.4564, 0.4582, 0.4586, 0.4626, 0.4648, 0.465, 0.4666, 0.4666, 0.472, 0.4728, 0.4716, 0.471, 0.471, 0.4746, 0.475, 0.4766, 0.4708, 0.4736, 0.4744, 0.4758, 0.4804, 0.475, 0.4768, 0.476, 0.477, 0.4794, 0.475, 0.476, 0.4798, 0.481, 0.4826, 0.4794, 0.4792, 0.48, 0.4796, 0.4808, 0.4844, 0.4784, 0.4824, 0.4746, 0.4808, 0.481, 0.4838, 0.4788, 0.483, 0.4832, 0.4792, 0.4808, 0.4842, 0.4826, 0.4782, 0.4818, 0.4794, 0.4814, 0.4798, 0.4804, 0.4812, 0.485, 0.4806, 0.4806, 0.4808, 0.481, 0.481, 0.4818, 0.4804, 0.4838, 0.481, 0.4776, 0.4804, 0.4826, 0.482, 0.4834, 0.484, 0.482, 0.4814, 0.4824, 0.481, 0.483, 0.4812, 0.4818, 0.4838, 0.48, 0.4836, 0.4804, 0.4802, 0.4816, 0.4818, 0.482, 0.4838, 0.4838, 0.4818, 0.4842, 0.4818, 0.479, 0.4798, 0.4806, 0.4798, 0.4804, 0.4814, 0.484, 0.481, 0.4792, 0.481, 0.4784, 0.4824, 0.479, 0.4814, 0.4812]",
         "2_1000_1e-05"
        ],
        [
         "3",
         "3",
         "4",
         "1000",
         "0.0001",
         "1456.21604180336",
         "1.0",
         "0.4808",
         "0.492",
         "[[203  35  16  22  12  14  44  57  37  58]\n [ 42 273  71  16  28  20  21  19  14  12]\n [  8  40 328  12  27  28  18  13  10  10]\n [ 26  15   6 263  24  10  36  43  14  49]\n [ 20  23  33  32 270  77  17  16  18  12]\n [ 13  25  35   6  79 302  15  13   9  16]\n [ 58  14  25  27  20  20 149  90  60  37]\n [ 45  16   7  31  11  10 106 170  53  42]\n [ 41  12   5  14  10  19  51  29 241  46]\n [ 70  30  19  44  15   9  34  36  38 221]]",
         "[0.4066, 0.4392, 0.4546, 0.466, 0.48, 0.4698, 0.4714, 0.4692, 0.465, 0.4692, 0.4684, 0.4652, 0.4642, 0.4668, 0.4634, 0.4702, 0.4696, 0.47, 0.4588, 0.4548, 0.463, 0.4508, 0.4664, 0.4626, 0.474, 0.4628, 0.4758, 0.4806, 0.4802, 0.482, 0.479, 0.4802, 0.4812, 0.4804, 0.481, 0.4816, 0.4816, 0.4814, 0.4818, 0.483, 0.4816, 0.4796, 0.4794, 0.4822, 0.4796, 0.4822, 0.4802, 0.4828, 0.4792, 0.4814, 0.4794, 0.4808, 0.4802, 0.4806, 0.4806, 0.4806, 0.479, 0.4804, 0.4808, 0.4806, 0.4808, 0.48, 0.4822, 0.4808, 0.4816, 0.4818, 0.4816, 0.482, 0.482, 0.4804, 0.481, 0.4818, 0.4808, 0.4832, 0.4822, 0.481, 0.481, 0.4812, 0.4822, 0.4816, 0.4818, 0.4812, 0.482, 0.481, 0.4818, 0.4822, 0.4826, 0.4818, 0.4824, 0.4824, 0.4828, 0.4822, 0.483, 0.4824, 0.4826, 0.483, 0.484, 0.4826, 0.4814, 0.4824, 0.482, 0.4824, 0.4832, 0.483, 0.4812, 0.4826, 0.4812, 0.4818, 0.4822, 0.482, 0.4832, 0.4822, 0.4816, 0.482, 0.4812, 0.4822, 0.482, 0.4816, 0.4818, 0.4804, 0.4816, 0.4808, 0.4802, 0.4806, 0.4808, 0.48, 0.4796, 0.4802, 0.4806, 0.4808, 0.48, 0.4802, 0.4814, 0.4808, 0.4808, 0.4818, 0.4804, 0.4804, 0.4808, 0.48, 0.48, 0.4798, 0.481, 0.481, 0.4794, 0.479, 0.4808]",
         "4_1000_0.0001"
        ],
        [
         "4",
         "4",
         "1",
         "1000",
         "0.0001",
         "835.5365505218506",
         "1.0",
         "0.4744",
         "0.481",
         "[[194  38  16  26  13  12  32  53  44  70]\n [ 37 268  67  11  30  22  22  18   9  32]\n [ 14  50 313  15  24  24  15  15  11  13]\n [ 35  18   5 250  20  14  43  29  11  61]\n [ 18  26  35  34 264  80  18  12  21  10]\n [ 10  32  47   9  76 280  24   6  12  17]\n [ 58  13  20  36  19  13 156  91  65  29]\n [ 42  15   6  28   8  10 113 185  43  41]\n [ 35   9   6  10  15  15  43  28 253  54]\n [ 75  29  13  52  12  12  33  34  39 217]]",
         "[0.3994, 0.4242, 0.4378, 0.4482, 0.4588, 0.4558, 0.4638, 0.4592, 0.4598, 0.472, 0.4636, 0.4672, 0.4626, 0.4704, 0.4682, 0.4626, 0.4638, 0.4718, 0.4668, 0.4644, 0.4708, 0.468, 0.4614, 0.4656, 0.4646, 0.467, 0.4654, 0.4622, 0.4698, 0.4636, 0.4704, 0.4666, 0.4686, 0.4662, 0.4668, 0.4564, 0.4668, 0.466, 0.4644, 0.4676, 0.4654, 0.4644, 0.4684, 0.4646, 0.47, 0.4658, 0.4676, 0.4654, 0.4656, 0.4682, 0.4654, 0.4726, 0.4634, 0.467, 0.4662, 0.4664, 0.4688, 0.4678, 0.472, 0.4668, 0.4722, 0.4706, 0.4656, 0.4682, 0.4692, 0.4682, 0.4708, 0.4702, 0.4648, 0.4676, 0.468, 0.4642, 0.4706, 0.4728, 0.4734, 0.469, 0.4658, 0.4722, 0.4724, 0.4686, 0.463, 0.4726, 0.473, 0.469, 0.4714, 0.474, 0.4672, 0.4664, 0.4674, 0.473, 0.462, 0.4384, 0.4618, 0.4682, 0.4708, 0.4706, 0.4726, 0.4708, 0.474, 0.4704, 0.4678, 0.4712, 0.4702, 0.471, 0.47, 0.473, 0.4708, 0.4696, 0.4748, 0.4728, 0.4702, 0.4742, 0.4724, 0.4752, 0.4728, 0.4712, 0.4746, 0.476, 0.4722, 0.47, 0.4678, 0.4714, 0.4748, 0.4746, 0.4756, 0.4722, 0.4724, 0.4706, 0.4382, 0.458, 0.4692, 0.4716, 0.4736, 0.4734, 0.4736, 0.4734, 0.4744, 0.473, 0.4724, 0.4722, 0.473, 0.4728, 0.4716, 0.4742, 0.4718, 0.4736, 0.4728, 0.4706, 0.471, 0.4696, 0.473, 0.4718, 0.4716, 0.4732, 0.4736, 0.4738, 0.471, 0.4724, 0.4692, 0.4716, 0.4718, 0.4724, 0.4736, 0.4736, 0.4716, 0.4738, 0.4702, 0.4744]",
         "1_1000_0.0001"
        ],
        [
         "5",
         "5",
         "1",
         "200",
         "1e-05",
         "160.686872959137",
         "0.744",
         "0.468",
         "0.4748",
         "[[173  44  15  36  10  27  29  53  53  58]\n [ 37 270  72  24  36  28  16  13  10  10]\n [  8  41 323  12  31  41  13  12   4   9]\n [ 24  17  10 266  20  12  28  44  14  51]\n [ 12  24  44  35 267  93  10   8  17   8]\n [  9  18  35  17  94 288  19  11   9  13]\n [ 47  12  23  22  36  20 147 100  67  26]\n [ 33  13   8  30  16  10 115 166  56  44]\n [ 31   7   8  15  13  18  50  28 256  42]\n [ 58  26  15  69  14  13  34  42  47 198]]",
         "[0.2282, 0.266, 0.2894, 0.311, 0.3238, 0.339, 0.3442, 0.3536, 0.362, 0.3688, 0.3746, 0.3824, 0.3852, 0.3956, 0.3956, 0.3972, 0.4, 0.4016, 0.4048, 0.4068, 0.4092, 0.4116, 0.411, 0.4104, 0.4128, 0.4152, 0.4146, 0.4172, 0.4204, 0.4204, 0.4226, 0.4258, 0.4266, 0.429, 0.4268, 0.4308, 0.4326, 0.4322, 0.4342, 0.4326, 0.4366, 0.4352, 0.4358, 0.4356, 0.4414, 0.4388, 0.4402, 0.4382, 0.4406, 0.44, 0.442, 0.4414, 0.4436, 0.446, 0.444, 0.4444, 0.4464, 0.4464, 0.4508, 0.4482, 0.4468, 0.4512, 0.449, 0.4504, 0.4526, 0.4508, 0.4542, 0.4522, 0.454, 0.4558, 0.455, 0.4544, 0.4538, 0.456, 0.4558, 0.459, 0.4576, 0.458, 0.4572, 0.4564, 0.4622, 0.4608, 0.4596, 0.4592, 0.4622, 0.4618, 0.4626, 0.4632, 0.4604, 0.4636, 0.4614, 0.4644, 0.4644, 0.464, 0.4628, 0.4634, 0.4676, 0.464, 0.463, 0.4656, 0.4634, 0.4634, 0.4656, 0.465, 0.4662, 0.4654, 0.4672, 0.4638, 0.4652, 0.4656, 0.468, 0.469, 0.4676, 0.468, 0.4666, 0.4678, 0.4662, 0.4668, 0.4708, 0.4648, 0.4668, 0.4676, 0.4676, 0.4682, 0.463, 0.4676, 0.4698, 0.465, 0.465, 0.4686, 0.4674, 0.4692, 0.4666, 0.4662, 0.4676, 0.4646, 0.4664, 0.4658, 0.4674, 0.4658, 0.465, 0.4656, 0.468, 0.47, 0.4664, 0.4652, 0.4664, 0.4668, 0.4648, 0.4634, 0.4656, 0.465, 0.4662, 0.4646, 0.467, 0.4652, 0.4662, 0.4666, 0.4668, 0.465, 0.4682, 0.4672, 0.469, 0.467, 0.4658, 0.4648, 0.4688, 0.4658, 0.468]",
         "1_200_1e-05"
        ],
        [
         "6",
         "6",
         "2",
         "200",
         "1e-05",
         "164.9713778495789",
         "0.7739333333333334",
         "0.4642",
         "0.4696",
         "[[158  36  16  36  13  25  47  54  43  70]\n [ 43 254  79  29  29  29  15  14  11  13]\n [ 14  46 323  10  25  36  10  21   3   6]\n [ 29  14   8 257  27  17  37  40  14  43]\n [ 13  20  37  22 278 100  12   8  15  13]\n [ 11  20  33  16  87 297  13  10  12  14]\n [ 31  12  23  30  27  20 176  86  67  28]\n [ 35   6  16  42   9  16 104 173  53  37]\n [ 27   9   7  18  20  21  40  30 243  53]\n [ 54  35  13  59  15  15  36  43  45 201]]",
         "[0.205, 0.257, 0.287, 0.311, 0.3276, 0.344, 0.355, 0.362, 0.372, 0.3776, 0.3836, 0.3858, 0.3908, 0.3988, 0.3992, 0.4026, 0.4058, 0.4108, 0.4124, 0.414, 0.4152, 0.4196, 0.4208, 0.4266, 0.427, 0.4284, 0.4298, 0.432, 0.4304, 0.4336, 0.4352, 0.4376, 0.4368, 0.4382, 0.4412, 0.4406, 0.4436, 0.4446, 0.443, 0.4476, 0.4494, 0.4502, 0.4488, 0.45, 0.4474, 0.451, 0.4508, 0.4542, 0.4536, 0.4522, 0.4536, 0.452, 0.4546, 0.4516, 0.4516, 0.4572, 0.4576, 0.4512, 0.4566, 0.4564, 0.4556, 0.457, 0.4582, 0.4568, 0.4584, 0.457, 0.4594, 0.4602, 0.4612, 0.4624, 0.4612, 0.4618, 0.4636, 0.4616, 0.4648, 0.4624, 0.465, 0.4672, 0.467, 0.4676, 0.466, 0.4658, 0.4668, 0.466, 0.4684, 0.4682, 0.4668, 0.467, 0.4664, 0.4684, 0.4694, 0.4686, 0.4666, 0.4692, 0.469, 0.4704, 0.4696, 0.4688, 0.4684, 0.4692, 0.4692, 0.4664, 0.4688, 0.4674, 0.4684, 0.4698, 0.469, 0.469, 0.4698, 0.4688, 0.469, 0.4696, 0.47, 0.472, 0.469, 0.47, 0.4696, 0.4682, 0.4706, 0.4706, 0.4702, 0.4716, 0.4688, 0.4704, 0.4674, 0.47, 0.4692, 0.4706, 0.4708, 0.4686, 0.4692, 0.4694, 0.4696, 0.4676, 0.469, 0.4684, 0.4688, 0.466, 0.4712, 0.468, 0.4678, 0.4678, 0.469, 0.468, 0.4682, 0.4676, 0.4684, 0.4674, 0.4672, 0.4664, 0.4674, 0.467, 0.4658, 0.4666, 0.4664, 0.4644, 0.4658, 0.468, 0.466, 0.4648, 0.4652, 0.4662, 0.4652, 0.4642]",
         "2_200_1e-05"
        ],
        [
         "7",
         "7",
         "2",
         "1000",
         "0.001",
         "396.0149710178375",
         "0.9861333333333333",
         "0.4592",
         "0.4618",
         "[[171  36  20  34  12  15  46  66  37  61]\n [ 25 263  77  12  33  34  30  20   9  13]\n [ 10  39 327  11  22  28  17  24   7   9]\n [ 19  13   5 265  20  10  38  64   9  43]\n [ 11  22  50  20 250  90  28  19  13  15]\n [  7  20  45  16  98 276  20  13   9   9]\n [ 41  11  19  28  25  11 161 122  51  31]\n [ 29   4   6  41  15   9  90 230  31  36]\n [ 30   9   3  19  17  13  42  45 241  49]\n [ 65  43  14  60  16  18  32  49  41 178]]",
         "[0.382, 0.4424, 0.445, 0.4652, 0.4582, 0.4508, 0.4552, 0.462, 0.4558, 0.4724, 0.4654, 0.46, 0.4618, 0.4612, 0.46, 0.4494, 0.4482, 0.4644, 0.459, 0.44, 0.4616, 0.4476, 0.453, 0.4596, 0.461, 0.469, 0.4646, 0.461, 0.4636, 0.4638, 0.448, 0.4526, 0.462, 0.4588, 0.4556, 0.46, 0.4608, 0.449, 0.4556, 0.4526, 0.4482, 0.4648, 0.4498, 0.46, 0.4534, 0.447, 0.4626, 0.4588, 0.4448, 0.4436, 0.4548, 0.4526, 0.4446, 0.4512, 0.456, 0.4538, 0.4588, 0.4684, 0.457, 0.4592]",
         "2_1000_0.001"
        ],
        [
         "8",
         "8",
         "4",
         "200",
         "1e-05",
         "190.7843225002289",
         "0.8446",
         "0.4576",
         "0.4652",
         "[[176  41  11  33  13  16  41  51  47  69]\n [ 26 272  74  21  41  25  21  12   6  18]\n [ 12  54 311  12  22  41  18  12   3   9]\n [ 33  16   9 252  32  10  19  43  13  59]\n [ 13  17  37  30 270  88  16  14  19  14]\n [  7  26  40   9  95 277  23  14  12  10]\n [ 37  14  20  31  25  23 149 101  65  35]\n [ 51  14  12  36  10  13  95 167  56  37]\n [ 36  10   7  10  14  11  44  31 256  49]\n [ 68  29  11  48  21  12  34  42  57 194]]",
         "[0.219, 0.256, 0.2778, 0.297, 0.3174, 0.3336, 0.3472, 0.3546, 0.359, 0.368, 0.3782, 0.3804, 0.3856, 0.3912, 0.396, 0.3998, 0.4012, 0.4042, 0.4078, 0.4116, 0.4146, 0.4148, 0.419, 0.417, 0.4204, 0.4252, 0.4232, 0.4272, 0.4288, 0.4284, 0.4336, 0.4326, 0.4338, 0.4324, 0.4328, 0.4354, 0.436, 0.4348, 0.4362, 0.437, 0.4382, 0.4374, 0.4368, 0.4384, 0.4362, 0.4392, 0.4414, 0.4412, 0.4398, 0.4434, 0.4392, 0.4446, 0.4414, 0.4448, 0.4446, 0.4448, 0.4442, 0.4462, 0.4466, 0.4484, 0.447, 0.4446, 0.4464, 0.449, 0.449, 0.4484, 0.4482, 0.4484, 0.4492, 0.451, 0.451, 0.4478, 0.449, 0.4526, 0.4502, 0.4528, 0.4528, 0.4532, 0.4488, 0.451, 0.45, 0.4546, 0.4526, 0.4512, 0.4536, 0.4514, 0.4564, 0.455, 0.453, 0.4524, 0.4554, 0.4546, 0.4574, 0.4564, 0.4552, 0.4582, 0.46, 0.4574, 0.4566, 0.4568, 0.4572, 0.4576, 0.4596, 0.458, 0.4586, 0.46, 0.461, 0.4604, 0.4594, 0.4604, 0.4614, 0.462, 0.4622, 0.4618, 0.4636, 0.4622, 0.4618, 0.4606, 0.4648, 0.463, 0.4626, 0.4624, 0.4624, 0.4634, 0.4612, 0.4646, 0.4588, 0.4618, 0.4646, 0.46, 0.4626, 0.4616, 0.461, 0.4584, 0.4602, 0.4584, 0.4608, 0.4616, 0.4608, 0.4594, 0.4596, 0.4576, 0.4568, 0.4596, 0.461, 0.4602, 0.4576, 0.4574, 0.4564, 0.4584, 0.458, 0.4592, 0.4562, 0.4574, 0.459, 0.4592, 0.4562, 0.4588, 0.4588, 0.4588, 0.4546, 0.4564, 0.4564, 0.4564, 0.4562, 0.4562, 0.4566, 0.458, 0.4576]",
         "4_200_1e-05"
        ],
        [
         "9",
         "9",
         "4",
         "200",
         "0.001",
         "64.32650542259216",
         "0.9824666666666667",
         "0.4544",
         "0.4636",
         "[[160  40  12  44  10  21  37  51  64  59]\n [ 45 259  66  30  25  33  16  12  14  16]\n [ 13  28 325  14  23  40  20  16   5  10]\n [ 35  15   6 248  23  15  36  39  23  46]\n [ 18  24  33  34 238 114  14  12  18  13]\n [  8  20  43  20  63 304  23  11  11  10]\n [ 39  13  15  21  21  26 160 106  76  23]\n [ 40   9   7  26  16  21 130 148  65  29]\n [ 19   3   6  17   5  19  54  30 275  40]\n [ 59  29  14  50  15  13  38  35  69 194]]",
         "[0.3972, 0.4146, 0.4358, 0.4368, 0.4486, 0.45, 0.4622, 0.4508, 0.4472, 0.4488, 0.4458, 0.452, 0.4474, 0.4462, 0.444, 0.4472, 0.4448, 0.4404, 0.4404, 0.4472, 0.4456, 0.4466, 0.449, 0.4478, 0.4566, 0.4444, 0.4454, 0.4394, 0.4336, 0.4332, 0.4448, 0.433, 0.4446, 0.4508, 0.4546, 0.4362, 0.4372, 0.4546, 0.4446, 0.4396, 0.4432, 0.4384, 0.439, 0.436, 0.4424, 0.4456, 0.4354, 0.4496, 0.4482, 0.4394, 0.4396, 0.4372, 0.43, 0.448, 0.451, 0.445, 0.4544]",
         "4_200_0.001"
        ],
        [
         "10",
         "10",
         "1",
         "200",
         "0.0001",
         "73.77918219566345",
         "0.9746666666666667",
         "0.4538",
         "0.4566",
         "[[190  35  13  30  12  18  48  45  45  62]\n [ 56 224  84  21  43  30  15  24   7  12]\n [ 13  37 329  11  29  31  12  13   7  12]\n [ 26   9  10 262  27  14  27  42  17  52]\n [ 16  12  41  32 278  85  14  11  22   7]\n [ 11  18  36  15  86 294  13  14   9  17]\n [ 46   8  24  31  26  25 154  91  59  36]\n [ 29  12  10  34  14   9 102 179  55  47]\n [ 35   7   6  14  14  18  50  33 238  53]\n [ 64  23  20  66  20  10  38  33  42 200]]",
         "[0.3586, 0.401, 0.4262, 0.4342, 0.4382, 0.4408, 0.4502, 0.4544, 0.4478, 0.464, 0.4588, 0.4554, 0.4576, 0.4614, 0.461, 0.46, 0.458, 0.4564, 0.461, 0.4592, 0.4592, 0.4636, 0.4654, 0.4648, 0.4626, 0.4658, 0.463, 0.4696, 0.4652, 0.4664, 0.4658, 0.4688, 0.4654, 0.461, 0.46, 0.4604, 0.4612, 0.4652, 0.4554, 0.4628, 0.4622, 0.4622, 0.4634, 0.4646, 0.461, 0.462, 0.4566, 0.4578, 0.4566, 0.4568, 0.4606, 0.4562, 0.4562, 0.4568, 0.453, 0.4574, 0.4574, 0.4598, 0.4548, 0.4526, 0.4568, 0.4538, 0.4564, 0.4592, 0.4524, 0.4538, 0.4504, 0.456, 0.4546, 0.4532, 0.4526, 0.452, 0.4556, 0.4514, 0.4482, 0.4516, 0.4494, 0.4538]",
         "1_200_0.0001"
        ],
        [
         "11",
         "11",
         "4",
         "1000",
         "1e-05",
         "853.8535912036896",
         "0.9998666666666667",
         "0.4538",
         "0.477",
         "[[159  50  16  34  13  14  37  51  48  76]\n [ 26 287  70  28  28  24  20  16   6  11]\n [ 11  44 326   9  26  35  16  13   5   9]\n [ 25  17  10 267  19  14  24  46  15  49]\n [ 17  29  37  37 253  97   7   9  22  10]\n [  7  27  39  20  78 303  12   2   9  16]\n [ 33  13  25  32  20  20 147 101  75  34]\n [ 29   9   8  34  10  13 110 189  55  34]\n [ 21   6   6  19  10  15  47  32 261  51]\n [ 50  35  21  58  11  14  38  37  49 203]]",
         "[0.2898, 0.3408, 0.3744, 0.3982, 0.4118, 0.4186, 0.4254, 0.4292, 0.4398, 0.4412, 0.4482, 0.4464, 0.4532, 0.4598, 0.4594, 0.458, 0.4626, 0.4646, 0.4664, 0.4664, 0.4702, 0.467, 0.4708, 0.4726, 0.4726, 0.4736, 0.4754, 0.472, 0.4784, 0.4742, 0.473, 0.4746, 0.4736, 0.4732, 0.4728, 0.479, 0.4738, 0.4714, 0.4726, 0.4718, 0.4666, 0.472, 0.473, 0.468, 0.4664, 0.4706, 0.465, 0.4658, 0.46, 0.4678, 0.466, 0.4632, 0.4648, 0.4654, 0.463, 0.4598, 0.4634, 0.4652, 0.4618, 0.4592, 0.464, 0.457, 0.4602, 0.4548, 0.4592, 0.4582, 0.4624, 0.4622, 0.4558, 0.4572, 0.4582, 0.4586, 0.4568, 0.4588, 0.4552, 0.4572, 0.459, 0.4548, 0.457, 0.457, 0.4536, 0.4554, 0.4522, 0.4558, 0.4546, 0.4538]",
         "4_1000_1e-05"
        ],
        [
         "12",
         "12",
         "4",
         "1000",
         "0.001",
         "804.7011778354645",
         "0.9835333333333334",
         "0.4534",
         "0.4564",
         "[[171  43  12  19  10  20  52  63  49  59]\n [ 45 267  70  19  29  27  18  13   9  19]\n [ 12  54 318   7  26  33  12  14   9   9]\n [ 22  22   7 238  20  13  29  63  13  59]\n [ 16  30  39  27 264  78  10  18  19  17]\n [ 12  28  36   7  88 280  13  18   9  22]\n [ 51  24  26  23  19  15 132 117  56  37]\n [ 40  14  10  29  10  15  73 217  47  36]\n [ 42   8   6  10  17  15  32  44 254  40]\n [ 53  42  18  44   7  14  31  52  59 196]]",
         "[0.3926, 0.4164, 0.4332, 0.4584, 0.4488, 0.4634, 0.4502, 0.453, 0.4648, 0.4626, 0.441, 0.4498, 0.452, 0.455, 0.4552, 0.4622, 0.4534, 0.4636, 0.4588, 0.4534, 0.4624, 0.4486, 0.4564, 0.4596, 0.4562, 0.4558, 0.4612, 0.4578, 0.456, 0.4632, 0.448, 0.4674, 0.465, 0.4506, 0.45, 0.4526, 0.4478, 0.4482, 0.4554, 0.4524, 0.4494, 0.4496, 0.4506, 0.4478, 0.452, 0.4648, 0.4382, 0.4492, 0.4646, 0.4542, 0.455, 0.451, 0.4454, 0.4562, 0.446, 0.4502, 0.4556, 0.4444, 0.4522, 0.4554, 0.451, 0.4582, 0.4524, 0.4562, 0.4556, 0.4468, 0.43, 0.4372, 0.4532, 0.439, 0.4598, 0.4658, 0.4578, 0.4426, 0.4562, 0.4492, 0.4512, 0.4518, 0.4414, 0.4414, 0.4576, 0.4534]",
         "4_1000_0.001"
        ],
        [
         "13",
         "13",
         "2",
         "200",
         "0.001",
         "251.0777778625488",
         "0.9977333333333334",
         "0.4486",
         "0.4608",
         "[[185  33  20  28  17  13  46  50  51  55]\n [ 39 256  67  21  40  18  27  18  11  19]\n [ 12  36 323  17  26  31  23  13   4   9]\n [ 35  14   3 257  20  13  40  36  16  52]\n [ 23  23  32  35 259  82  23  10  18  13]\n [ 12  17  42  12  91 279  22  16   6  16]\n [ 47  14  25  31  19  19 160  90  64  31]\n [ 41  10   7  40   9   6 109 170  61  38]\n [ 40   5  10  19  15  19  48  34 231  47]\n [ 65  36  21  58  13  11  35  28  45 204]]",
         "[0.3884, 0.4206, 0.4316, 0.4326, 0.4444, 0.4418, 0.4496, 0.4438, 0.4496, 0.4386, 0.4502, 0.4426, 0.4526, 0.449, 0.4426, 0.4462, 0.443, 0.4538, 0.4344, 0.4498, 0.449, 0.4464, 0.4288, 0.4428, 0.4466, 0.4476, 0.435, 0.4442, 0.4496, 0.4278, 0.4326, 0.4368, 0.4368, 0.4486, 0.4404, 0.449, 0.4332, 0.4328, 0.4346, 0.44, 0.448, 0.4418, 0.4322, 0.429, 0.4434, 0.4378, 0.4318, 0.4498, 0.452, 0.452, 0.443, 0.454, 0.451, 0.43, 0.42, 0.4376, 0.4248, 0.4276, 0.4364, 0.4374, 0.4366, 0.4364, 0.4414, 0.4474, 0.4488, 0.4528, 0.455, 0.454, 0.4554, 0.4552, 0.456, 0.455, 0.456, 0.456, 0.4546, 0.4542, 0.4538, 0.4536, 0.4548, 0.4546, 0.4558, 0.4552, 0.4546, 0.4542, 0.454, 0.4546, 0.4538, 0.454, 0.4536, 0.4532, 0.4538, 0.4534, 0.4544, 0.4558, 0.456, 0.456, 0.456, 0.4572, 0.4568, 0.4564, 0.456, 0.4562, 0.4558, 0.4562, 0.4554, 0.4568, 0.4558, 0.4548, 0.4562, 0.4572, 0.457, 0.457, 0.4558, 0.4568, 0.4576, 0.4574, 0.4588, 0.4576, 0.4588, 0.4586, 0.4586, 0.4586, 0.4578, 0.4582, 0.4586, 0.459, 0.459, 0.4586, 0.4584, 0.4606, 0.4594, 0.4594, 0.4592, 0.46, 0.4594, 0.46, 0.4594, 0.4592, 0.4594, 0.4594, 0.4598, 0.459, 0.4598, 0.4604, 0.4598, 0.4606, 0.4604, 0.4604, 0.4606, 0.4602, 0.4602, 0.4608, 0.4602, 0.4614, 0.4608, 0.462, 0.4618, 0.4622, 0.4616, 0.4622, 0.4618, 0.4614, 0.462, 0.4624, 0.4626, 0.4624, 0.463, 0.4622, 0.4624, 0.463, 0.463, 0.463, 0.463, 0.4638, 0.463, 0.4636, 0.4636, 0.4632, 0.4632, 0.4624, 0.4628, 0.4636, 0.4632, 0.4632, 0.4642, 0.4632, 0.4634, 0.4628, 0.4622, 0.4636, 0.4624, 0.4642, 0.463, 0.4636, 0.4628, 0.4632, 0.4636, 0.4634, 0.4628, 0.4648, 0.4634, 0.4622, 0.4628, 0.4642, 0.4618, 0.4626, 0.4642, 0.3226, 0.3438, 0.388, 0.4126, 0.4374, 0.4292, 0.4372, 0.4346, 0.4362, 0.4422, 0.4416, 0.4406, 0.4456, 0.4348, 0.4464, 0.444, 0.4334, 0.4328, 0.4346, 0.429, 0.4274, 0.4376, 0.4458, 0.4424, 0.4446, 0.4344, 0.4416, 0.436, 0.444, 0.4406, 0.4368, 0.4274, 0.4424, 0.4268, 0.4346, 0.4448, 0.437, 0.4418, 0.4422, 0.4452, 0.4408, 0.4406, 0.4486]",
         "2_200_0.001"
        ],
        [
         "14",
         "14",
         "2",
         "200",
         "0.0001",
         "70.42459297180176",
         "0.9950666666666667",
         "0.4482",
         "0.4458",
         "[[190  42  16  31  18  20  38  33  48  62]\n [ 43 264  60  28  37  35  22   7   7  13]\n [ 15  47 312  12  32  38  16   9   5   8]\n [ 43  11   8 262  23  14  37  29  17  42]\n [ 12  16  29  33 288  91   9  14  14  12]\n [ 17  15  31  13  97 301  13   8   7  11]\n [ 64  16  21  29  27  22 161  80  53  27]\n [ 50   7   8  35  16  11 125 147  61  31]\n [ 53   8   6  16  15  22  47  26 216  59]\n [ 77  34  12  57  18  16  32  30  45 195]]",
         "[0.3656, 0.3986, 0.4188, 0.4302, 0.4384, 0.437, 0.447, 0.4574, 0.453, 0.4528, 0.4574, 0.459, 0.4644, 0.462, 0.4652, 0.4626, 0.4604, 0.4628, 0.4586, 0.4672, 0.4638, 0.4632, 0.462, 0.4616, 0.4524, 0.4624, 0.4606, 0.4574, 0.457, 0.4606, 0.4612, 0.4552, 0.457, 0.4594, 0.457, 0.455, 0.4504, 0.453, 0.4578, 0.4542, 0.4544, 0.4528, 0.4538, 0.456, 0.4544, 0.4558, 0.4564, 0.4532, 0.4486, 0.4468, 0.452, 0.453, 0.4494, 0.4536, 0.4522, 0.4484, 0.4504, 0.4472, 0.4482, 0.452, 0.4486, 0.451, 0.4518, 0.4542, 0.4438, 0.4502, 0.4456, 0.4488, 0.4434, 0.4482]",
         "2_200_0.0001"
        ],
        [
         "15",
         "15",
         "1",
         "200",
         "0.001",
         "74.55913352966309",
         "0.9995333333333334",
         "0.4412",
         "0.4524",
         "[[160  39  17  34  18  17  45  47  59  62]\n [ 34 249  65  29  32  25  22  19  13  28]\n [ 15  43 304  13  30  34  18  12  16   9]\n [ 29  19   2 275  17  11  39  34  24  36]\n [ 17  24  41  39 261  77   8  13  26  12]\n [  8  25  40  16  88 279  14  13  17  13]\n [ 39  11  16  44  28  22 152  78  79  31]\n [ 28  13   7  46  10  10 133 139  72  33]\n [ 25   6   4  18  10  13  39  33 273  47]\n [ 44  31  16  63  11  14  40  34  83 180]]",
         "[0.399, 0.4116, 0.4084, 0.4136, 0.436, 0.436, 0.4426, 0.4394, 0.4416, 0.4412, 0.4292, 0.44, 0.4404, 0.4348, 0.4326, 0.4356, 0.4344, 0.4404, 0.4342, 0.433, 0.4362, 0.4432, 0.4368, 0.4238, 0.4434, 0.427, 0.4544, 0.441, 0.4472, 0.4368, 0.4342, 0.4168, 0.429, 0.4434, 0.42, 0.422, 0.4342, 0.4422, 0.4358, 0.4346, 0.438, 0.4356, 0.444, 0.4424, 0.4328, 0.4362, 0.4304, 0.422, 0.4232, 0.4404, 0.4366, 0.441, 0.4416, 0.4338, 0.4362, 0.4386, 0.438, 0.4312, 0.4332, 0.4448, 0.4362, 0.4428, 0.4456, 0.4398, 0.4244, 0.3884, 0.4212, 0.4336, 0.4318, 0.4272, 0.4392, 0.4408, 0.4418, 0.444, 0.4452, 0.4408, 0.4412]",
         "1_200_0.001"
        ],
        [
         "16",
         "16",
         "1",
         "1000",
         "0.001",
         "553.0117275714874",
         "0.9667333333333333",
         "0.4386",
         "0.4482",
         "[[151  37  17  42  11  19  67  48  50  56]\n [ 31 252  63  24  39  21  30  27   5  24]\n [  8  52 297  15  29  31  17  25   6  14]\n [ 17  21   3 278  17   7  49  35  16  43]\n [ 11  21  28  31 291  65  27   6  22  16]\n [  7  25  33  12  87 287  25   6  11  20]\n [ 36  14  18  42  18  16 174  95  62  25]\n [ 31   7   4  37  13   5 125 184  46  39]\n [ 21   7   4  22  14  14  69  28 246  43]\n [ 50  30  14  68  18   7  41  39  59 190]]",
         "[0.3694, 0.3932, 0.4144, 0.4102, 0.4316, 0.4454, 0.4308, 0.4508, 0.4392, 0.4464, 0.4376, 0.4396, 0.4346, 0.4416, 0.4372, 0.4424, 0.4194, 0.4444, 0.422, 0.4412, 0.4532, 0.4324, 0.4464, 0.437, 0.4442, 0.4224, 0.4346, 0.434, 0.4416, 0.4292, 0.4442, 0.4366, 0.445, 0.4424, 0.4436, 0.4464, 0.447, 0.438, 0.4526, 0.4256, 0.4404, 0.4486, 0.4356, 0.4294, 0.4366, 0.4438, 0.4468, 0.4394, 0.4484, 0.4266, 0.4448, 0.4436, 0.4402, 0.441, 0.45, 0.4472, 0.4368, 0.4388, 0.4482, 0.4366, 0.47, 0.442, 0.4428, 0.4552, 0.4478, 0.4404, 0.4376, 0.4282, 0.4446, 0.452, 0.4414, 0.4518, 0.4432, 0.446, 0.4584, 0.4464, 0.4408, 0.4584, 0.4504, 0.4608, 0.4674, 0.4652, 0.4632, 0.4616, 0.4492, 0.4456, 0.4378, 0.441, 0.4472, 0.4504, 0.4428, 0.4512, 0.4532, 0.4546, 0.449, 0.4484, 0.4398, 0.4314, 0.4426, 0.4376, 0.447, 0.434, 0.45, 0.4494, 0.4458, 0.4458, 0.438, 0.4356, 0.4474, 0.43, 0.4386]",
         "1_1000_0.001"
        ],
        [
         "17",
         "17",
         "1",
         "50",
         "1e-05",
         "148.976603269577",
         "0.6544666666666666",
         "0.4372",
         "0.4436",
         "[[166  35  25  33  16  21  45  42  52  63]\n [ 44 237  72  21  40  29  22  19  13  19]\n [ 10  45 317   9  25  35  20  14   7  12]\n [ 31  17  11 256  27  14  44  27  20  39]\n [ 12  22  59  35 236  93  13  12  16  20]\n [ 14  24  35  16  94 277  21   7  12  13]\n [ 39   9  26  27  24  27 153  91  71  33]\n [ 42   7  14  34   8  14 131 154  45  42]\n [ 36  11   6  15  14  18  66  36 218  48]\n [ 61  29  13  57  17  12  38  34  49 206]]",
         "[0.154, 0.189, 0.2186, 0.2378, 0.2564, 0.2688, 0.2782, 0.2884, 0.295, 0.304, 0.3122, 0.317, 0.3206, 0.327, 0.3298, 0.3356, 0.3376, 0.3412, 0.3464, 0.348, 0.3512, 0.3518, 0.3552, 0.3578, 0.3594, 0.3612, 0.3622, 0.3662, 0.3654, 0.3688, 0.3694, 0.3722, 0.373, 0.3746, 0.3758, 0.3768, 0.3786, 0.3818, 0.3826, 0.386, 0.3876, 0.3862, 0.3888, 0.39, 0.3926, 0.3906, 0.3918, 0.3912, 0.3952, 0.3972, 0.3972, 0.3962, 0.3958, 0.3982, 0.3982, 0.3986, 0.3992, 0.3986, 0.3986, 0.4016, 0.4004, 0.4012, 0.4042, 0.4036, 0.4018, 0.406, 0.4044, 0.4054, 0.4058, 0.4078, 0.4076, 0.409, 0.408, 0.4092, 0.4096, 0.4118, 0.4112, 0.4132, 0.413, 0.4144, 0.4156, 0.4162, 0.4158, 0.415, 0.418, 0.4162, 0.4178, 0.416, 0.4182, 0.4216, 0.417, 0.4158, 0.422, 0.4196, 0.4186, 0.4184, 0.4208, 0.418, 0.4196, 0.4202, 0.421, 0.4208, 0.4194, 0.4224, 0.42, 0.4212, 0.4222, 0.4212, 0.4224, 0.4218, 0.4224, 0.4224, 0.4248, 0.4234, 0.423, 0.4248, 0.4252, 0.4248, 0.4266, 0.427, 0.4258, 0.4286, 0.4276, 0.4296, 0.4278, 0.4284, 0.4304, 0.4278, 0.4282, 0.4292, 0.4314, 0.428, 0.4306, 0.4346, 0.4332, 0.4324, 0.4312, 0.4322, 0.433, 0.4336, 0.4326, 0.435, 0.433, 0.436, 0.4344, 0.4352, 0.4356, 0.4336, 0.4346, 0.4344, 0.4348, 0.4328, 0.4334, 0.4358, 0.4332, 0.435, 0.436, 0.4358, 0.4362, 0.433, 0.4364, 0.437, 0.4364, 0.4354, 0.4366, 0.4336, 0.436, 0.4354, 0.4336, 0.4362, 0.436, 0.4348, 0.4358, 0.4338, 0.4344, 0.435, 0.437, 0.4358, 0.4364, 0.4356, 0.4346, 0.4346, 0.4376, 0.4344, 0.4348, 0.4354, 0.4346, 0.437, 0.4352, 0.4348, 0.4362, 0.4366, 0.4354, 0.4358, 0.4356, 0.4384, 0.438, 0.4362, 0.4378, 0.4364, 0.4356, 0.4356, 0.4358, 0.436, 0.4364, 0.436, 0.434, 0.4374, 0.4364, 0.4364, 0.4362, 0.4364, 0.4356, 0.4372, 0.4376, 0.4364, 0.438, 0.4362, 0.44, 0.4376, 0.4368, 0.44, 0.438, 0.4382, 0.438, 0.4388, 0.4382, 0.4378, 0.4374, 0.4394, 0.439, 0.439, 0.4394, 0.4374, 0.4384, 0.439, 0.4388, 0.4402, 0.4388, 0.4404, 0.4402, 0.4396, 0.4406, 0.44, 0.4396, 0.44, 0.4394, 0.4396, 0.4398, 0.4412, 0.441, 0.4408, 0.4416, 0.438, 0.4402, 0.4404, 0.4406, 0.4418, 0.4404, 0.4418, 0.441, 0.4414, 0.4422, 0.4418, 0.4406, 0.4402, 0.4414, 0.4412, 0.4406, 0.44, 0.4398, 0.4408, 0.4418, 0.4418, 0.4402, 0.4386, 0.4402, 0.4404, 0.44, 0.4402, 0.4406, 0.4408, 0.4408, 0.4408, 0.4404, 0.4396, 0.4404, 0.441, 0.4388, 0.44, 0.4396, 0.4406, 0.4406, 0.4418, 0.44, 0.4398, 0.4402, 0.4416, 0.4398, 0.441, 0.4402, 0.439, 0.4408, 0.4406, 0.44, 0.4418, 0.4402, 0.4414, 0.4408, 0.4402, 0.4402, 0.4422, 0.4428, 0.4416, 0.4408, 0.44, 0.4418, 0.4414, 0.4414, 0.4414, 0.4408, 0.4418, 0.4402, 0.4412, 0.4406, 0.442, 0.4422, 0.442, 0.4402, 0.4412, 0.442, 0.4414, 0.4434, 0.4404, 0.44, 0.4416, 0.4412, 0.4402, 0.4396, 0.4414, 0.4418, 0.4402, 0.4402, 0.4422, 0.4412, 0.4402, 0.4416, 0.4426, 0.4396, 0.4422, 0.4428, 0.4408, 0.4416, 0.4402, 0.4422, 0.4406, 0.4412, 0.4434, 0.442, 0.4418, 0.4406, 0.4408, 0.4434, 0.4406, 0.4418, 0.4408, 0.444, 0.4406, 0.442, 0.443, 0.441, 0.4408, 0.44, 0.4422, 0.4408, 0.4408, 0.441, 0.4422, 0.4402, 0.441, 0.4408, 0.442, 0.4408, 0.442, 0.441, 0.4408, 0.442, 0.44, 0.4402, 0.4404, 0.44, 0.4398, 0.44, 0.4406, 0.4404, 0.4382, 0.4412, 0.4388, 0.4406, 0.439, 0.4406, 0.4378, 0.438, 0.4382, 0.4394, 0.4372, 0.439, 0.4388, 0.4382, 0.4368, 0.4366, 0.4364, 0.438, 0.4362, 0.4362, 0.4354, 0.4372]",
         "1_50_1e-05"
        ],
        [
         "18",
         "18",
         "4",
         "200",
         "0.0001",
         "70.03902196884155",
         "0.9996",
         "0.4348",
         "0.4426",
         "[[155  35  16  44  17  20  51  35  60  65]\n [ 27 240  82  24  53  39  20   7   9  15]\n [  6  33 328   7  32  48  15   3   9  13]\n [ 31  10   9 247  41  10  38  35  12  53]\n [  7  13  29  27 290 106  14   8  17   7]\n [  2  12  36  17  88 314  14   3  10  17]\n [ 30  10  25  38  30  23 181  71  67  25]\n [ 30   9  12  44  15  19 116 147  62  37]\n [ 23   4   7  19  16  18  63  19 243  56]\n [ 51  33  13  56  23  19  38  27  58 198]]",
         "[0.3478, 0.3966, 0.4206, 0.427, 0.4414, 0.4544, 0.4496, 0.455, 0.4582, 0.457, 0.4634, 0.4686, 0.4664, 0.4606, 0.463, 0.46, 0.4594, 0.4656, 0.4532, 0.4596, 0.458, 0.4584, 0.4556, 0.4508, 0.4548, 0.4516, 0.4496, 0.4518, 0.4504, 0.446, 0.4448, 0.4458, 0.445, 0.4438, 0.4364, 0.4354, 0.4408, 0.4374, 0.436, 0.4298, 0.4354, 0.4376, 0.4358, 0.4352, 0.4382, 0.4358, 0.4366, 0.4382, 0.4392, 0.4362, 0.4372, 0.4296, 0.4396, 0.4332, 0.4334, 0.4296, 0.431, 0.4322, 0.4234, 0.4342, 0.4378, 0.4348]",
         "4_200_0.0001"
        ],
        [
         "19",
         "19",
         "4",
         "50",
         "1e-05",
         "97.55360579490662",
         "0.5957333333333333",
         "0.4308",
         "0.4372",
         "[[151  42  22  37   9  25  53  52  55  52]\n [ 38 234  93  30  38  27  25  12   9  10]\n [  7  53 311  11  25  38  29  10   4   6]\n [ 36  18  11 237  27  12  42  39  17  47]\n [  4  17  51  32 256  98  15  17  18  10]\n [  9  13  45  16  98 278  17  14  10  13]\n [ 37  12  25  37  28  22 143  98  72  26]\n [ 38  10   8  48  15  14 103 164  63  28]\n [ 33   6   9  18  17  17  55  25 241  47]\n [ 68  35  13  59  11  22  43  47  60 158]]",
         "[0.1158, 0.1302, 0.1456, 0.166, 0.1978, 0.2194, 0.2352, 0.2498, 0.2562, 0.2642, 0.2702, 0.2778, 0.2826, 0.2872, 0.2918, 0.2952, 0.3008, 0.303, 0.3072, 0.3118, 0.3172, 0.3222, 0.3252, 0.3276, 0.3296, 0.3324, 0.334, 0.3348, 0.3382, 0.3392, 0.3408, 0.344, 0.3466, 0.3482, 0.35, 0.35, 0.3534, 0.3542, 0.357, 0.3582, 0.3588, 0.3648, 0.3674, 0.367, 0.3692, 0.3706, 0.375, 0.3746, 0.3756, 0.3792, 0.379, 0.3802, 0.381, 0.3852, 0.3842, 0.3854, 0.387, 0.387, 0.388, 0.3896, 0.39, 0.3906, 0.3908, 0.392, 0.3932, 0.3938, 0.396, 0.3968, 0.3952, 0.3974, 0.3992, 0.3986, 0.4002, 0.4008, 0.4014, 0.4018, 0.4032, 0.403, 0.404, 0.4036, 0.4052, 0.4044, 0.407, 0.406, 0.4068, 0.408, 0.408, 0.4086, 0.409, 0.4106, 0.4114, 0.4118, 0.4114, 0.413, 0.4116, 0.4134, 0.4116, 0.4128, 0.4124, 0.4126, 0.4134, 0.4146, 0.4122, 0.414, 0.4156, 0.4122, 0.4158, 0.4156, 0.4156, 0.4162, 0.4146, 0.4146, 0.4176, 0.4172, 0.4186, 0.4172, 0.4192, 0.421, 0.418, 0.4202, 0.4208, 0.421, 0.4204, 0.4206, 0.422, 0.4216, 0.4224, 0.4218, 0.4228, 0.425, 0.4228, 0.4234, 0.424, 0.4232, 0.423, 0.4244, 0.4248, 0.4262, 0.4254, 0.4254, 0.4258, 0.4256, 0.427, 0.4268, 0.4268, 0.4256, 0.4266, 0.4268, 0.4262, 0.4258, 0.427, 0.4276, 0.4256, 0.424, 0.4254, 0.4254, 0.4276, 0.4266, 0.425, 0.4264, 0.4268, 0.427, 0.4256, 0.4274, 0.4266, 0.4272, 0.4268, 0.4272, 0.4278, 0.4268, 0.4284, 0.4292, 0.4278, 0.4278, 0.428, 0.4266, 0.4286, 0.429, 0.4276, 0.4296, 0.4314, 0.431, 0.4308, 0.429, 0.4296, 0.4298, 0.431, 0.4312, 0.4308, 0.43, 0.4312, 0.4322, 0.431, 0.4318, 0.432, 0.4318, 0.431, 0.4312, 0.4316, 0.4322, 0.4316, 0.4346, 0.4324, 0.4336, 0.4314, 0.4324, 0.431, 0.4324, 0.4316, 0.4324, 0.4324, 0.4302, 0.43, 0.4336, 0.4324, 0.4316, 0.432, 0.4298, 0.4314, 0.4304, 0.4306, 0.4314, 0.4314, 0.4288, 0.4306, 0.4288, 0.4302, 0.431, 0.4294, 0.4294, 0.4304, 0.4286, 0.4298, 0.4314, 0.429, 0.4306, 0.4286, 0.4304, 0.4302, 0.4292, 0.4288, 0.4304, 0.4292, 0.4316, 0.4302, 0.43, 0.4282, 0.4292, 0.428, 0.4294, 0.4306, 0.4308]",
         "4_50_1e-05"
        ],
        [
         "20",
         "20",
         "1",
         "50",
         "0.0001",
         "45.73590517044067",
         "0.8074",
         "0.428",
         "0.4262",
         "[[156  41  19  26  26  17  36  50  62  65]\n [ 37 252  73  17  41  29  23  13  15  16]\n [ 10  61 295  10  35  30  16  15   9  13]\n [ 42  23  13 243  24   8  34  36  20  43]\n [ 16  23  44  35 254  88  21   5  13  19]\n [ 11  32  42  16  85 272  21   7  13  14]\n [ 40  22  17  32  31  17 144  93  77  27]\n [ 41   7   9  33  20  11 103 163  56  48]\n [ 31  11   5  21  13  17  51  30 241  48]\n [ 69  33  19  52  14  11  28  34  65 191]]",
         "[0.3046, 0.3512, 0.3704, 0.3882, 0.3958, 0.4026, 0.4086, 0.4138, 0.4136, 0.4176, 0.4206, 0.4184, 0.4196, 0.4228, 0.4246, 0.4212, 0.423, 0.422, 0.4278, 0.4252, 0.4282, 0.4326, 0.4296, 0.4272, 0.4328, 0.43, 0.4334, 0.4354, 0.4372, 0.435, 0.4374, 0.438, 0.4324, 0.4322, 0.4364, 0.4352, 0.441, 0.4344, 0.431, 0.439, 0.4346, 0.4382, 0.4394, 0.4322, 0.4408, 0.4374, 0.4362, 0.4356, 0.4382, 0.4344, 0.435, 0.4312, 0.4406, 0.4374, 0.4386, 0.4392, 0.4382, 0.4368, 0.4374, 0.4358, 0.4342, 0.437, 0.4376, 0.4358, 0.4336, 0.435, 0.4352, 0.4348, 0.4364, 0.4336, 0.4344, 0.4342, 0.4422, 0.4354, 0.4308, 0.433, 0.4312, 0.4314, 0.4284, 0.4324, 0.4342, 0.4294, 0.4332, 0.429, 0.4272, 0.4284, 0.4326, 0.4294, 0.433, 0.4328, 0.429, 0.4308, 0.431, 0.426, 0.4272, 0.4294, 0.4316, 0.4296, 0.434, 0.423, 0.4256, 0.4312, 0.4308, 0.4278, 0.4308, 0.4242, 0.4288, 0.4286, 0.4288, 0.4248, 0.4286, 0.4254, 0.4252, 0.427, 0.4276, 0.4288, 0.4266, 0.4258, 0.4258, 0.4342, 0.4206, 0.4304, 0.428]",
         "1_50_0.0001"
        ],
        [
         "21",
         "21",
         "2",
         "50",
         "0.0001",
         "38.37017035484314",
         "0.8242666666666667",
         "0.424",
         "0.4276",
         "[[166  48  14  37  15  14  46  46  45  67]\n [ 33 248  81  26  37  21  26  15  12  17]\n [ 18  50 309  14  26  35  15  15   2  10]\n [ 32  15  15 246  29  15  37  40  22  35]\n [  8  21  40  42 235 104  23  11  16  18]\n [  8  30  48  17  95 256  15  16  11  17]\n [ 45  13  24  18  32  23 145 105  63  32]\n [ 41   5  15  48  14  13 108 155  53  39]\n [ 28   9   7  14  15  21  45  38 232  59]\n [ 49  31  20  54  15  15  36  48  51 197]]",
         "[0.2568, 0.319, 0.349, 0.3738, 0.3856, 0.3896, 0.4016, 0.4042, 0.4072, 0.4112, 0.4156, 0.4212, 0.4192, 0.4236, 0.4266, 0.4272, 0.4278, 0.4268, 0.4288, 0.4268, 0.4286, 0.4302, 0.4276, 0.428, 0.4352, 0.4328, 0.4324, 0.4322, 0.4302, 0.435, 0.432, 0.433, 0.4316, 0.4334, 0.436, 0.4354, 0.4324, 0.4296, 0.4332, 0.4314, 0.4324, 0.4344, 0.432, 0.434, 0.4356, 0.4336, 0.434, 0.4328, 0.432, 0.4318, 0.4376, 0.4274, 0.4326, 0.433, 0.4338, 0.4346, 0.4378, 0.432, 0.4352, 0.4318, 0.4318, 0.434, 0.433, 0.434, 0.428, 0.43, 0.4306, 0.4274, 0.4336, 0.4296, 0.4344, 0.4338, 0.43, 0.4328, 0.4292, 0.4332, 0.4322, 0.4288, 0.431, 0.4266, 0.4268, 0.4284, 0.4282, 0.4224, 0.4276, 0.4284, 0.4258, 0.4278, 0.4248, 0.4264, 0.428, 0.4278, 0.4248, 0.424, 0.4224, 0.4266, 0.424, 0.4228, 0.4238, 0.4276, 0.426, 0.4248, 0.4222, 0.4242, 0.4188, 0.4266, 0.424]",
         "2_50_0.0001"
        ],
        [
         "22",
         "22",
         "2",
         "50",
         "1e-05",
         "88.53829455375671",
         "0.5918",
         "0.4236",
         "0.422",
         "[[146  46  19  37  18  18  51  47  58  58]\n [ 39 243  94  20  45  25  16  13  11  10]\n [  7  56 304  10  36  26  24  20   5   6]\n [ 38  16  10 238  25  13  42  45  23  36]\n [  9  17  49  32 236 119  17  19  12   8]\n [ 11  25  38  17  80 271  30  17  18   6]\n [ 33   9  24  27  25  26 177  81  77  21]\n [ 42  11   8  38  13  12 124 141  70  32]\n [ 30  11   6  21  18  20  67  32 221  42]\n [ 62  36  14  68  17  11  39  38  79 152]]",
         "[0.1194, 0.153, 0.1852, 0.207, 0.2248, 0.2428, 0.2586, 0.2694, 0.2832, 0.2906, 0.2976, 0.3042, 0.31, 0.3146, 0.3228, 0.3266, 0.3306, 0.337, 0.3402, 0.3442, 0.3476, 0.3502, 0.3504, 0.3534, 0.3528, 0.3568, 0.3582, 0.3616, 0.3618, 0.3658, 0.3656, 0.3682, 0.3676, 0.3684, 0.3724, 0.3752, 0.3754, 0.3776, 0.3786, 0.3794, 0.3796, 0.3814, 0.3826, 0.385, 0.3844, 0.387, 0.3862, 0.3876, 0.3868, 0.3884, 0.39, 0.3904, 0.3882, 0.3906, 0.3908, 0.3914, 0.3926, 0.3938, 0.3954, 0.3972, 0.3986, 0.3974, 0.3976, 0.397, 0.3962, 0.3988, 0.4004, 0.4006, 0.4002, 0.401, 0.399, 0.4006, 0.4026, 0.4016, 0.4012, 0.403, 0.4038, 0.4054, 0.4044, 0.4074, 0.408, 0.4052, 0.4076, 0.406, 0.4052, 0.4064, 0.4056, 0.4058, 0.4078, 0.4094, 0.4082, 0.4078, 0.4086, 0.4098, 0.4096, 0.41, 0.4098, 0.4098, 0.4112, 0.4116, 0.4104, 0.4096, 0.4112, 0.4098, 0.4104, 0.4114, 0.4114, 0.412, 0.4118, 0.4114, 0.4122, 0.4116, 0.413, 0.412, 0.4124, 0.4138, 0.4146, 0.4134, 0.4152, 0.4146, 0.415, 0.4142, 0.4142, 0.4142, 0.4138, 0.4144, 0.4134, 0.4142, 0.4134, 0.4134, 0.416, 0.4152, 0.4148, 0.414, 0.4158, 0.4144, 0.4152, 0.4154, 0.415, 0.416, 0.415, 0.4156, 0.4164, 0.415, 0.4164, 0.4156, 0.4164, 0.4158, 0.4154, 0.4168, 0.4168, 0.416, 0.4164, 0.416, 0.4176, 0.4172, 0.4182, 0.4188, 0.4182, 0.4188, 0.4188, 0.4194, 0.4194, 0.4196, 0.4204, 0.42, 0.4212, 0.4214, 0.4204, 0.4202, 0.4226, 0.4222, 0.4222, 0.4226, 0.4222, 0.4216, 0.4238, 0.421, 0.4218, 0.4236, 0.4224, 0.423, 0.4222, 0.4238, 0.4222, 0.4228, 0.4236, 0.4226, 0.4242, 0.4234, 0.4242, 0.4234, 0.4232, 0.4238, 0.4238, 0.4252, 0.4258, 0.4248, 0.425, 0.4258, 0.4248, 0.425, 0.4246, 0.4244, 0.4244, 0.4234, 0.4246, 0.4234, 0.424, 0.4234, 0.4238, 0.4222, 0.423, 0.4238, 0.4228, 0.4232, 0.4234, 0.422, 0.4232, 0.4224, 0.4232, 0.4224, 0.4218, 0.4216, 0.423, 0.4224, 0.4228, 0.4228, 0.4242, 0.4232, 0.4228, 0.4228, 0.4236, 0.4218, 0.4234, 0.423, 0.4228, 0.4224, 0.4218, 0.4234, 0.4246, 0.4252, 0.4234, 0.424, 0.4232, 0.4246, 0.4236]",
         "2_50_1e-05"
        ],
        [
         "23",
         "23",
         "4",
         "50",
         "0.0001",
         "31.08946442604065",
         "0.7972666666666667",
         "0.4184",
         "0.4188",
         "[[139  47  19  45  12  20  47  49  71  49]\n [ 36 267  79  31  35  18  17  13  13   7]\n [ 11  52 308  13  40  26  22   8   8   6]\n [ 31  14  13 255  25  12  31  42  22  41]\n [  7  22  52  40 217 109  25  12  22  12]\n [  6  25  37  19  86 282  23  15  12   8]\n [ 33  14  30  26  23  23 143  95  83  30]\n [ 29  11  11  47   8  14  99 168  72  32]\n [ 30   7  10  21  11  13  44  30 256  46]\n [ 55  34  15  53  13  13  41  38  74 180]]",
         "[0.2788, 0.3432, 0.3664, 0.3868, 0.3924, 0.3968, 0.404, 0.4102, 0.4112, 0.4192, 0.4206, 0.427, 0.426, 0.4288, 0.4244, 0.4278, 0.4324, 0.4316, 0.4366, 0.4346, 0.4324, 0.4342, 0.4398, 0.4358, 0.4362, 0.4332, 0.4394, 0.4382, 0.4334, 0.443, 0.4384, 0.4416, 0.4364, 0.4362, 0.4344, 0.4408, 0.437, 0.4338, 0.4376, 0.4394, 0.4384, 0.434, 0.44, 0.438, 0.4382, 0.4368, 0.4406, 0.4328, 0.4386, 0.4344, 0.434, 0.4352, 0.433, 0.4314, 0.439, 0.4356, 0.4306, 0.4344, 0.4358, 0.4342, 0.4342, 0.4282, 0.4296, 0.43, 0.429, 0.4248, 0.4266, 0.4252, 0.4296, 0.4276, 0.426, 0.4252, 0.4212, 0.4222, 0.4236, 0.4226, 0.4234, 0.4254, 0.423, 0.4184]",
         "4_50_0.0001"
        ],
        [
         "24",
         "24",
         "1",
         "50",
         "0.001",
         "21.6652820110321",
         "0.9078",
         "0.4102",
         "0.4038",
         "[[135  39  17  53  16  21  43  52  40  82]\n [ 36 242  79  39  36  25  14  18   5  22]\n [  9  54 293  17  46  37   8  15   5  10]\n [ 22  16   4 268  30  13  35  33  14  51]\n [  9  23  24  36 286  80  19   9  11  21]\n [  8  27  34  15 114 266  13  11   8  17]\n [ 44  18  24  44  28  24 153  83  42  40]\n [ 29  15   8  49  20  15 111 156  38  50]\n [ 25  12  10  26  16  23  67  30 173  86]\n [ 50  27  16  67  16  19  41  43  31 206]]",
         "[0.3834, 0.4014, 0.407, 0.4054, 0.4166, 0.4356, 0.423, 0.4268, 0.4354, 0.431, 0.4334, 0.4272, 0.4286, 0.4308, 0.4276, 0.433, 0.431, 0.4284, 0.4226, 0.4274, 0.4342, 0.4324, 0.4248, 0.4186, 0.424, 0.4242, 0.425, 0.422, 0.4158, 0.4178, 0.4198, 0.4166, 0.4146, 0.424, 0.4184, 0.4056, 0.4174, 0.4188, 0.412, 0.413, 0.4152, 0.4176, 0.4144, 0.421, 0.407, 0.4186, 0.4144, 0.4146, 0.4154, 0.416, 0.4126, 0.413, 0.4038, 0.4202, 0.405, 0.4102]",
         "1_50_0.001"
        ],
        [
         "25",
         "25",
         "2",
         "50",
         "0.001",
         "20.09845161437988",
         "0.9370666666666667",
         "0.396",
         "0.4078",
         "[[159  58  17  42  18  17  31  45  44  67]\n [ 50 247  69  26  51  28  19   8   5  13]\n [ 18  69 291  10  47  24  15  11   5   4]\n [ 31  18  10 235  31  12  35  41  27  46]\n [  7  18  45  37 293  66  13  13  19   7]\n [ 15  28  54  15 113 240  24   7  10   7]\n [ 51  23  35  25  36   9 138  90  68  25]\n [ 49  15  19  33  22  10 108 142  60  33]\n [ 42   7  10  20  18  17  53  34 211  56]\n [ 66  43  20  37  19   8  47  32  38 206]]",
         "[0.3708, 0.396, 0.419, 0.4268, 0.4098, 0.4324, 0.4248, 0.4164, 0.43, 0.4132, 0.4234, 0.4298, 0.4244, 0.4222, 0.4234, 0.4208, 0.4148, 0.4148, 0.4218, 0.4068, 0.4028, 0.4176, 0.4142, 0.408, 0.409, 0.3976, 0.4036, 0.4024, 0.4044, 0.4042, 0.4008, 0.393, 0.3982, 0.395, 0.3966, 0.397, 0.3914, 0.3996, 0.396, 0.391, 0.3984, 0.3978, 0.3924, 0.3984, 0.3982, 0.3914, 0.3868, 0.3952, 0.3918, 0.39, 0.3886, 0.3912, 0.3864, 0.3926, 0.3888, 0.396]",
         "2_50_0.001"
        ],
        [
         "26",
         "26",
         "4",
         "50",
         "0.001",
         "25.24482989311218",
         "0.8994666666666666",
         "0.3926",
         "0.4016",
         "[[171  38  17  37  11  16  34  42  47  85]\n [ 43 248  77  29  33  29  12  16   8  21]\n [  7  47 320   8  39  28  12  15   2  16]\n [ 53  17   8 210  21  15  26  57  19  60]\n [  8  21  45  30 247  97  10  18  21  21]\n [ 11  26  47  14  86 272  20  10  16  11]\n [ 53  11  26  29  21  21  95 129  65  50]\n [ 54  11  14  30  10   6  78 187  51  50]\n [ 47   4   7  20  12  10  33  47 235  53]\n [ 77  35  15  43  18   7  25  38  61 197]]",
         "[0.3446, 0.3884, 0.403, 0.4042, 0.4126, 0.4312, 0.4206, 0.4234, 0.435, 0.426, 0.4246, 0.4314, 0.4258, 0.4244, 0.4364, 0.4262, 0.421, 0.4294, 0.4218, 0.4196, 0.4284, 0.4092, 0.4284, 0.4054, 0.4084, 0.4214, 0.414, 0.4096, 0.4052, 0.4136, 0.4132, 0.4184, 0.4178, 0.4134, 0.4138, 0.4014, 0.4026, 0.4114, 0.4158, 0.4122, 0.4104, 0.4074, 0.4142, 0.4114, 0.3984, 0.4048, 0.3982, 0.4064, 0.4082, 0.4034, 0.3982, 0.3978, 0.4042, 0.4104, 0.4042, 0.4056, 0.4026, 0.4048, 0.3958, 0.395, 0.3926, 0.4032, 0.3998, 0.3936, 0.3926]",
         "4_50_0.001"
        ]
       ],
       "shape": {
        "columns": 11,
        "rows": 27
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>hidden_layers</th>\n",
       "      <th>n_neurons</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>train_time</th>\n",
       "      <th>train_score</th>\n",
       "      <th>val_score</th>\n",
       "      <th>test_score</th>\n",
       "      <th>confusion_matrices</th>\n",
       "      <th>val_accuracy_over_epochs</th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>736.960688</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.4878</td>\n",
       "      <td>0.4862</td>\n",
       "      <td>[[197  36  14  29  13  10  41  56  43  59]\\n [...</td>\n",
       "      <td>[0.4156, 0.4394, 0.4518, 0.4658, 0.4708, 0.475...</td>\n",
       "      <td>2_1000_0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>1119.730063</td>\n",
       "      <td>0.983867</td>\n",
       "      <td>0.4822</td>\n",
       "      <td>0.4860</td>\n",
       "      <td>[[181  41  14  30  13  15  43  53  41  67]\\n [...</td>\n",
       "      <td>[0.2848, 0.3324, 0.3556, 0.3758, 0.3894, 0.399...</td>\n",
       "      <td>1_1000_1e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>824.780240</td>\n",
       "      <td>0.991067</td>\n",
       "      <td>0.4812</td>\n",
       "      <td>0.4762</td>\n",
       "      <td>[[179  39  13  30  18  19  41  52  55  52]\\n [...</td>\n",
       "      <td>[0.3122, 0.353, 0.3866, 0.4032, 0.4154, 0.4216...</td>\n",
       "      <td>2_1000_1e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>1456.216042</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.4808</td>\n",
       "      <td>0.4920</td>\n",
       "      <td>[[203  35  16  22  12  14  44  57  37  58]\\n [...</td>\n",
       "      <td>[0.4066, 0.4392, 0.4546, 0.466, 0.48, 0.4698, ...</td>\n",
       "      <td>4_1000_0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>835.536551</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.4744</td>\n",
       "      <td>0.4810</td>\n",
       "      <td>[[194  38  16  26  13  12  32  53  44  70]\\n [...</td>\n",
       "      <td>[0.3994, 0.4242, 0.4378, 0.4482, 0.4588, 0.455...</td>\n",
       "      <td>1_1000_0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>200</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>160.686873</td>\n",
       "      <td>0.744000</td>\n",
       "      <td>0.4680</td>\n",
       "      <td>0.4748</td>\n",
       "      <td>[[173  44  15  36  10  27  29  53  53  58]\\n [...</td>\n",
       "      <td>[0.2282, 0.266, 0.2894, 0.311, 0.3238, 0.339, ...</td>\n",
       "      <td>1_200_1e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>164.971378</td>\n",
       "      <td>0.773933</td>\n",
       "      <td>0.4642</td>\n",
       "      <td>0.4696</td>\n",
       "      <td>[[158  36  16  36  13  25  47  54  43  70]\\n [...</td>\n",
       "      <td>[0.205, 0.257, 0.287, 0.311, 0.3276, 0.344, 0....</td>\n",
       "      <td>2_200_1e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>396.014971</td>\n",
       "      <td>0.986133</td>\n",
       "      <td>0.4592</td>\n",
       "      <td>0.4618</td>\n",
       "      <td>[[171  36  20  34  12  15  46  66  37  61]\\n [...</td>\n",
       "      <td>[0.382, 0.4424, 0.445, 0.4652, 0.4582, 0.4508,...</td>\n",
       "      <td>2_1000_0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>200</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>190.784323</td>\n",
       "      <td>0.844600</td>\n",
       "      <td>0.4576</td>\n",
       "      <td>0.4652</td>\n",
       "      <td>[[176  41  11  33  13  16  41  51  47  69]\\n [...</td>\n",
       "      <td>[0.219, 0.256, 0.2778, 0.297, 0.3174, 0.3336, ...</td>\n",
       "      <td>4_200_1e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>200</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>64.326505</td>\n",
       "      <td>0.982467</td>\n",
       "      <td>0.4544</td>\n",
       "      <td>0.4636</td>\n",
       "      <td>[[160  40  12  44  10  21  37  51  64  59]\\n [...</td>\n",
       "      <td>[0.3972, 0.4146, 0.4358, 0.4368, 0.4486, 0.45,...</td>\n",
       "      <td>4_200_0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>200</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>73.779182</td>\n",
       "      <td>0.974667</td>\n",
       "      <td>0.4538</td>\n",
       "      <td>0.4566</td>\n",
       "      <td>[[190  35  13  30  12  18  48  45  45  62]\\n [...</td>\n",
       "      <td>[0.3586, 0.401, 0.4262, 0.4342, 0.4382, 0.4408...</td>\n",
       "      <td>1_200_0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>853.853591</td>\n",
       "      <td>0.999867</td>\n",
       "      <td>0.4538</td>\n",
       "      <td>0.4770</td>\n",
       "      <td>[[159  50  16  34  13  14  37  51  48  76]\\n [...</td>\n",
       "      <td>[0.2898, 0.3408, 0.3744, 0.3982, 0.4118, 0.418...</td>\n",
       "      <td>4_1000_1e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>804.701178</td>\n",
       "      <td>0.983533</td>\n",
       "      <td>0.4534</td>\n",
       "      <td>0.4564</td>\n",
       "      <td>[[171  43  12  19  10  20  52  63  49  59]\\n [...</td>\n",
       "      <td>[0.3926, 0.4164, 0.4332, 0.4584, 0.4488, 0.463...</td>\n",
       "      <td>4_1000_0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>251.077778</td>\n",
       "      <td>0.997733</td>\n",
       "      <td>0.4486</td>\n",
       "      <td>0.4608</td>\n",
       "      <td>[[185  33  20  28  17  13  46  50  51  55]\\n [...</td>\n",
       "      <td>[0.3884, 0.4206, 0.4316, 0.4326, 0.4444, 0.441...</td>\n",
       "      <td>2_200_0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>70.424593</td>\n",
       "      <td>0.995067</td>\n",
       "      <td>0.4482</td>\n",
       "      <td>0.4458</td>\n",
       "      <td>[[190  42  16  31  18  20  38  33  48  62]\\n [...</td>\n",
       "      <td>[0.3656, 0.3986, 0.4188, 0.4302, 0.4384, 0.437...</td>\n",
       "      <td>2_200_0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>200</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>74.559134</td>\n",
       "      <td>0.999533</td>\n",
       "      <td>0.4412</td>\n",
       "      <td>0.4524</td>\n",
       "      <td>[[160  39  17  34  18  17  45  47  59  62]\\n [...</td>\n",
       "      <td>[0.399, 0.4116, 0.4084, 0.4136, 0.436, 0.436, ...</td>\n",
       "      <td>1_200_0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>553.011728</td>\n",
       "      <td>0.966733</td>\n",
       "      <td>0.4386</td>\n",
       "      <td>0.4482</td>\n",
       "      <td>[[151  37  17  42  11  19  67  48  50  56]\\n [...</td>\n",
       "      <td>[0.3694, 0.3932, 0.4144, 0.4102, 0.4316, 0.445...</td>\n",
       "      <td>1_1000_0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>148.976603</td>\n",
       "      <td>0.654467</td>\n",
       "      <td>0.4372</td>\n",
       "      <td>0.4436</td>\n",
       "      <td>[[166  35  25  33  16  21  45  42  52  63]\\n [...</td>\n",
       "      <td>[0.154, 0.189, 0.2186, 0.2378, 0.2564, 0.2688,...</td>\n",
       "      <td>1_50_1e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>200</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>70.039022</td>\n",
       "      <td>0.999600</td>\n",
       "      <td>0.4348</td>\n",
       "      <td>0.4426</td>\n",
       "      <td>[[155  35  16  44  17  20  51  35  60  65]\\n [...</td>\n",
       "      <td>[0.3478, 0.3966, 0.4206, 0.427, 0.4414, 0.4544...</td>\n",
       "      <td>4_200_0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>97.553606</td>\n",
       "      <td>0.595733</td>\n",
       "      <td>0.4308</td>\n",
       "      <td>0.4372</td>\n",
       "      <td>[[151  42  22  37   9  25  53  52  55  52]\\n [...</td>\n",
       "      <td>[0.1158, 0.1302, 0.1456, 0.166, 0.1978, 0.2194...</td>\n",
       "      <td>4_50_1e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>45.735905</td>\n",
       "      <td>0.807400</td>\n",
       "      <td>0.4280</td>\n",
       "      <td>0.4262</td>\n",
       "      <td>[[156  41  19  26  26  17  36  50  62  65]\\n [...</td>\n",
       "      <td>[0.3046, 0.3512, 0.3704, 0.3882, 0.3958, 0.402...</td>\n",
       "      <td>1_50_0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>38.370170</td>\n",
       "      <td>0.824267</td>\n",
       "      <td>0.4240</td>\n",
       "      <td>0.4276</td>\n",
       "      <td>[[166  48  14  37  15  14  46  46  45  67]\\n [...</td>\n",
       "      <td>[0.2568, 0.319, 0.349, 0.3738, 0.3856, 0.3896,...</td>\n",
       "      <td>2_50_0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>88.538295</td>\n",
       "      <td>0.591800</td>\n",
       "      <td>0.4236</td>\n",
       "      <td>0.4220</td>\n",
       "      <td>[[146  46  19  37  18  18  51  47  58  58]\\n [...</td>\n",
       "      <td>[0.1194, 0.153, 0.1852, 0.207, 0.2248, 0.2428,...</td>\n",
       "      <td>2_50_1e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>31.089464</td>\n",
       "      <td>0.797267</td>\n",
       "      <td>0.4184</td>\n",
       "      <td>0.4188</td>\n",
       "      <td>[[139  47  19  45  12  20  47  49  71  49]\\n [...</td>\n",
       "      <td>[0.2788, 0.3432, 0.3664, 0.3868, 0.3924, 0.396...</td>\n",
       "      <td>4_50_0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>21.665282</td>\n",
       "      <td>0.907800</td>\n",
       "      <td>0.4102</td>\n",
       "      <td>0.4038</td>\n",
       "      <td>[[135  39  17  53  16  21  43  52  40  82]\\n [...</td>\n",
       "      <td>[0.3834, 0.4014, 0.407, 0.4054, 0.4166, 0.4356...</td>\n",
       "      <td>1_50_0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>20.098452</td>\n",
       "      <td>0.937067</td>\n",
       "      <td>0.3960</td>\n",
       "      <td>0.4078</td>\n",
       "      <td>[[159  58  17  42  18  17  31  45  44  67]\\n [...</td>\n",
       "      <td>[0.3708, 0.396, 0.419, 0.4268, 0.4098, 0.4324,...</td>\n",
       "      <td>2_50_0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>25.244830</td>\n",
       "      <td>0.899467</td>\n",
       "      <td>0.3926</td>\n",
       "      <td>0.4016</td>\n",
       "      <td>[[171  38  17  37  11  16  34  42  47  85]\\n [...</td>\n",
       "      <td>[0.3446, 0.3884, 0.403, 0.4042, 0.4126, 0.4312...</td>\n",
       "      <td>4_50_0.001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index  hidden_layers  n_neurons  learning_rate   train_time  train_score  \\\n",
       "0       0              2       1000        0.00010   736.960688     1.000000   \n",
       "1       1              1       1000        0.00001  1119.730063     0.983867   \n",
       "2       2              2       1000        0.00001   824.780240     0.991067   \n",
       "3       3              4       1000        0.00010  1456.216042     1.000000   \n",
       "4       4              1       1000        0.00010   835.536551     1.000000   \n",
       "5       5              1        200        0.00001   160.686873     0.744000   \n",
       "6       6              2        200        0.00001   164.971378     0.773933   \n",
       "7       7              2       1000        0.00100   396.014971     0.986133   \n",
       "8       8              4        200        0.00001   190.784323     0.844600   \n",
       "9       9              4        200        0.00100    64.326505     0.982467   \n",
       "10     10              1        200        0.00010    73.779182     0.974667   \n",
       "11     11              4       1000        0.00001   853.853591     0.999867   \n",
       "12     12              4       1000        0.00100   804.701178     0.983533   \n",
       "13     13              2        200        0.00100   251.077778     0.997733   \n",
       "14     14              2        200        0.00010    70.424593     0.995067   \n",
       "15     15              1        200        0.00100    74.559134     0.999533   \n",
       "16     16              1       1000        0.00100   553.011728     0.966733   \n",
       "17     17              1         50        0.00001   148.976603     0.654467   \n",
       "18     18              4        200        0.00010    70.039022     0.999600   \n",
       "19     19              4         50        0.00001    97.553606     0.595733   \n",
       "20     20              1         50        0.00010    45.735905     0.807400   \n",
       "21     21              2         50        0.00010    38.370170     0.824267   \n",
       "22     22              2         50        0.00001    88.538295     0.591800   \n",
       "23     23              4         50        0.00010    31.089464     0.797267   \n",
       "24     24              1         50        0.00100    21.665282     0.907800   \n",
       "25     25              2         50        0.00100    20.098452     0.937067   \n",
       "26     26              4         50        0.00100    25.244830     0.899467   \n",
       "\n",
       "    val_score  test_score                                 confusion_matrices  \\\n",
       "0      0.4878      0.4862  [[197  36  14  29  13  10  41  56  43  59]\\n [...   \n",
       "1      0.4822      0.4860  [[181  41  14  30  13  15  43  53  41  67]\\n [...   \n",
       "2      0.4812      0.4762  [[179  39  13  30  18  19  41  52  55  52]\\n [...   \n",
       "3      0.4808      0.4920  [[203  35  16  22  12  14  44  57  37  58]\\n [...   \n",
       "4      0.4744      0.4810  [[194  38  16  26  13  12  32  53  44  70]\\n [...   \n",
       "5      0.4680      0.4748  [[173  44  15  36  10  27  29  53  53  58]\\n [...   \n",
       "6      0.4642      0.4696  [[158  36  16  36  13  25  47  54  43  70]\\n [...   \n",
       "7      0.4592      0.4618  [[171  36  20  34  12  15  46  66  37  61]\\n [...   \n",
       "8      0.4576      0.4652  [[176  41  11  33  13  16  41  51  47  69]\\n [...   \n",
       "9      0.4544      0.4636  [[160  40  12  44  10  21  37  51  64  59]\\n [...   \n",
       "10     0.4538      0.4566  [[190  35  13  30  12  18  48  45  45  62]\\n [...   \n",
       "11     0.4538      0.4770  [[159  50  16  34  13  14  37  51  48  76]\\n [...   \n",
       "12     0.4534      0.4564  [[171  43  12  19  10  20  52  63  49  59]\\n [...   \n",
       "13     0.4486      0.4608  [[185  33  20  28  17  13  46  50  51  55]\\n [...   \n",
       "14     0.4482      0.4458  [[190  42  16  31  18  20  38  33  48  62]\\n [...   \n",
       "15     0.4412      0.4524  [[160  39  17  34  18  17  45  47  59  62]\\n [...   \n",
       "16     0.4386      0.4482  [[151  37  17  42  11  19  67  48  50  56]\\n [...   \n",
       "17     0.4372      0.4436  [[166  35  25  33  16  21  45  42  52  63]\\n [...   \n",
       "18     0.4348      0.4426  [[155  35  16  44  17  20  51  35  60  65]\\n [...   \n",
       "19     0.4308      0.4372  [[151  42  22  37   9  25  53  52  55  52]\\n [...   \n",
       "20     0.4280      0.4262  [[156  41  19  26  26  17  36  50  62  65]\\n [...   \n",
       "21     0.4240      0.4276  [[166  48  14  37  15  14  46  46  45  67]\\n [...   \n",
       "22     0.4236      0.4220  [[146  46  19  37  18  18  51  47  58  58]\\n [...   \n",
       "23     0.4184      0.4188  [[139  47  19  45  12  20  47  49  71  49]\\n [...   \n",
       "24     0.4102      0.4038  [[135  39  17  53  16  21  43  52  40  82]\\n [...   \n",
       "25     0.3960      0.4078  [[159  58  17  42  18  17  31  45  44  67]\\n [...   \n",
       "26     0.3926      0.4016  [[171  38  17  37  11  16  34  42  47  85]\\n [...   \n",
       "\n",
       "                             val_accuracy_over_epochs             ID  \n",
       "0   [0.4156, 0.4394, 0.4518, 0.4658, 0.4708, 0.475...  2_1000_0.0001  \n",
       "1   [0.2848, 0.3324, 0.3556, 0.3758, 0.3894, 0.399...   1_1000_1e-05  \n",
       "2   [0.3122, 0.353, 0.3866, 0.4032, 0.4154, 0.4216...   2_1000_1e-05  \n",
       "3   [0.4066, 0.4392, 0.4546, 0.466, 0.48, 0.4698, ...  4_1000_0.0001  \n",
       "4   [0.3994, 0.4242, 0.4378, 0.4482, 0.4588, 0.455...  1_1000_0.0001  \n",
       "5   [0.2282, 0.266, 0.2894, 0.311, 0.3238, 0.339, ...    1_200_1e-05  \n",
       "6   [0.205, 0.257, 0.287, 0.311, 0.3276, 0.344, 0....    2_200_1e-05  \n",
       "7   [0.382, 0.4424, 0.445, 0.4652, 0.4582, 0.4508,...   2_1000_0.001  \n",
       "8   [0.219, 0.256, 0.2778, 0.297, 0.3174, 0.3336, ...    4_200_1e-05  \n",
       "9   [0.3972, 0.4146, 0.4358, 0.4368, 0.4486, 0.45,...    4_200_0.001  \n",
       "10  [0.3586, 0.401, 0.4262, 0.4342, 0.4382, 0.4408...   1_200_0.0001  \n",
       "11  [0.2898, 0.3408, 0.3744, 0.3982, 0.4118, 0.418...   4_1000_1e-05  \n",
       "12  [0.3926, 0.4164, 0.4332, 0.4584, 0.4488, 0.463...   4_1000_0.001  \n",
       "13  [0.3884, 0.4206, 0.4316, 0.4326, 0.4444, 0.441...    2_200_0.001  \n",
       "14  [0.3656, 0.3986, 0.4188, 0.4302, 0.4384, 0.437...   2_200_0.0001  \n",
       "15  [0.399, 0.4116, 0.4084, 0.4136, 0.436, 0.436, ...    1_200_0.001  \n",
       "16  [0.3694, 0.3932, 0.4144, 0.4102, 0.4316, 0.445...   1_1000_0.001  \n",
       "17  [0.154, 0.189, 0.2186, 0.2378, 0.2564, 0.2688,...     1_50_1e-05  \n",
       "18  [0.3478, 0.3966, 0.4206, 0.427, 0.4414, 0.4544...   4_200_0.0001  \n",
       "19  [0.1158, 0.1302, 0.1456, 0.166, 0.1978, 0.2194...     4_50_1e-05  \n",
       "20  [0.3046, 0.3512, 0.3704, 0.3882, 0.3958, 0.402...    1_50_0.0001  \n",
       "21  [0.2568, 0.319, 0.349, 0.3738, 0.3856, 0.3896,...    2_50_0.0001  \n",
       "22  [0.1194, 0.153, 0.1852, 0.207, 0.2248, 0.2428,...     2_50_1e-05  \n",
       "23  [0.2788, 0.3432, 0.3664, 0.3868, 0.3924, 0.396...    4_50_0.0001  \n",
       "24  [0.3834, 0.4014, 0.407, 0.4054, 0.4166, 0.4356...     1_50_0.001  \n",
       "25  [0.3708, 0.396, 0.419, 0.4268, 0.4098, 0.4324,...     2_50_0.001  \n",
       "26  [0.3446, 0.3884, 0.403, 0.4042, 0.4126, 0.4312...     4_50_0.001  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "previous_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "index_new",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "index_old",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "ID",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "6de32799-b2c9-41fa-ae4a-6e859ca6d0cf",
       "rows": [
        [
         "0",
         "0",
         "3",
         "4_1000_0.0001"
        ],
        [
         "1",
         "1",
         "0",
         "2_1000_0.0001"
        ],
        [
         "2",
         "2",
         "7",
         "2_1000_0.001"
        ],
        [
         "3",
         "3",
         "4",
         "1_1000_0.0001"
        ],
        [
         "4",
         "4",
         "16",
         "1_1000_0.001"
        ],
        [
         "5",
         "5",
         "12",
         "4_1000_0.001"
        ],
        [
         "6",
         "6",
         "9",
         "4_200_0.001"
        ],
        [
         "7",
         "7",
         "13",
         "2_200_0.001"
        ],
        [
         "8",
         "8",
         "14",
         "2_200_0.0001"
        ],
        [
         "9",
         "9",
         "18",
         "4_200_0.0001"
        ],
        [
         "10",
         "10",
         "26",
         "4_50_0.001"
        ],
        [
         "11",
         "11",
         "15",
         "1_200_0.001"
        ],
        [
         "12",
         "12",
         "10",
         "1_200_0.0001"
        ],
        [
         "13",
         "13",
         "25",
         "2_50_0.001"
        ],
        [
         "14",
         "14",
         "24",
         "1_50_0.001"
        ],
        [
         "15",
         "15",
         "11",
         "4_1000_1e-05"
        ],
        [
         "16",
         "16",
         "2",
         "2_1000_1e-05"
        ],
        [
         "17",
         "17",
         "20",
         "1_50_0.0001"
        ],
        [
         "18",
         "18",
         "21",
         "2_50_0.0001"
        ],
        [
         "19",
         "19",
         "1",
         "1_1000_1e-05"
        ],
        [
         "20",
         "20",
         "23",
         "4_50_0.0001"
        ],
        [
         "21",
         "21",
         "5",
         "1_200_1e-05"
        ],
        [
         "22",
         "22",
         "6",
         "2_200_1e-05"
        ],
        [
         "23",
         "23",
         "8",
         "4_200_1e-05"
        ],
        [
         "24",
         "24",
         "22",
         "2_50_1e-05"
        ],
        [
         "25",
         "25",
         "17",
         "1_50_1e-05"
        ],
        [
         "26",
         "26",
         "19",
         "4_50_1e-05"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 27
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index_new</th>\n",
       "      <th>index_old</th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4_1000_0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2_1000_0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>2_1000_0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1_1000_0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>1_1000_0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>4_1000_0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>4_200_0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>2_200_0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>2_200_0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>18</td>\n",
       "      <td>4_200_0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>26</td>\n",
       "      <td>4_50_0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "      <td>1_200_0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>1_200_0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>25</td>\n",
       "      <td>2_50_0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>24</td>\n",
       "      <td>1_50_0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>4_1000_1e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>2_1000_1e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>20</td>\n",
       "      <td>1_50_0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>21</td>\n",
       "      <td>2_50_0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>1_1000_1e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>23</td>\n",
       "      <td>4_50_0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>5</td>\n",
       "      <td>1_200_1e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>6</td>\n",
       "      <td>2_200_1e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>8</td>\n",
       "      <td>4_200_1e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>22</td>\n",
       "      <td>2_50_1e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>17</td>\n",
       "      <td>1_50_1e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>19</td>\n",
       "      <td>4_50_1e-05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index_new  index_old             ID\n",
       "0           0          3  4_1000_0.0001\n",
       "1           1          0  2_1000_0.0001\n",
       "2           2          7   2_1000_0.001\n",
       "3           3          4  1_1000_0.0001\n",
       "4           4         16   1_1000_0.001\n",
       "5           5         12   4_1000_0.001\n",
       "6           6          9    4_200_0.001\n",
       "7           7         13    2_200_0.001\n",
       "8           8         14   2_200_0.0001\n",
       "9           9         18   4_200_0.0001\n",
       "10         10         26     4_50_0.001\n",
       "11         11         15    1_200_0.001\n",
       "12         12         10   1_200_0.0001\n",
       "13         13         25     2_50_0.001\n",
       "14         14         24     1_50_0.001\n",
       "15         15         11   4_1000_1e-05\n",
       "16         16          2   2_1000_1e-05\n",
       "17         17         20    1_50_0.0001\n",
       "18         18         21    2_50_0.0001\n",
       "19         19          1   1_1000_1e-05\n",
       "20         20         23    4_50_0.0001\n",
       "21         21          5    1_200_1e-05\n",
       "22         22          6    2_200_1e-05\n",
       "23         23          8    4_200_1e-05\n",
       "24         24         22     2_50_1e-05\n",
       "25         25         17     1_50_1e-05\n",
       "26         26         19     4_50_1e-05"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Merge both to check positions\n",
    "merged_results = pd.merge(configurations_df, previous_results, on='ID', suffixes=('_new', '_old'))\n",
    "merged_results['val_score_diff'] = merged_results['val_score_new'] - merged_results['val_score_old']\n",
    "merged_results['position_diff'] = merged_results['index_new'] - merged_results['index_old']\n",
    "display(merged_results[['index_new', 'index_old', 'ID']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Convert to PyTorch tensors\n",
    "# X_train_tensor = torch.tensor(X_train, dtype=torch.float32) / 255.0  # Normalize to [0, 1]\n",
    "# y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "\n",
    "# X_test_tensor = torch.tensor(X_test, dtype=torch.float32) / 255.0  # Normalize to [0, 1]\n",
    "# y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "# # Create DataLoader for training and testing\n",
    "# train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "# train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "# test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "# test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 100, Loss: 2.340\n",
      "Epoch 1, Batch 200, Loss: 2.338\n",
      "Epoch 1, Batch 300, Loss: 2.338\n",
      "Epoch 1, Batch 400, Loss: 2.323\n",
      "Epoch 1, Batch 500, Loss: 2.327\n",
      "Epoch 1, Batch 600, Loss: 2.323\n",
      "Epoch 2, Batch 100, Loss: 2.311\n",
      "Epoch 2, Batch 200, Loss: 2.314\n",
      "Epoch 2, Batch 300, Loss: 2.308\n",
      "Epoch 2, Batch 400, Loss: 2.310\n",
      "Epoch 2, Batch 500, Loss: 2.307\n",
      "Epoch 2, Batch 600, Loss: 2.307\n",
      "Epoch 3, Batch 100, Loss: 2.304\n",
      "Epoch 3, Batch 200, Loss: 2.306\n",
      "Epoch 3, Batch 300, Loss: 2.304\n",
      "Epoch 3, Batch 400, Loss: 2.303\n",
      "Epoch 3, Batch 500, Loss: 2.304\n",
      "Epoch 3, Batch 600, Loss: 2.304\n",
      "Epoch 4, Batch 100, Loss: 2.303\n",
      "Epoch 4, Batch 200, Loss: 2.303\n",
      "Epoch 4, Batch 300, Loss: 2.303\n",
      "Epoch 4, Batch 400, Loss: 2.304\n",
      "Epoch 4, Batch 500, Loss: 2.302\n",
      "Epoch 4, Batch 600, Loss: 2.303\n",
      "Epoch 5, Batch 100, Loss: 2.303\n",
      "Epoch 5, Batch 200, Loss: 2.303\n",
      "Epoch 5, Batch 300, Loss: 2.303\n",
      "Epoch 5, Batch 400, Loss: 2.303\n",
      "Epoch 5, Batch 500, Loss: 2.302\n",
      "Epoch 5, Batch 600, Loss: 2.303\n",
      "Finished Training\n",
      "Accuracy of the model on the 10000 test images: 10.01%\n",
      "Predicted labels: [5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]\n",
      "True labels: [7 5 8 0 8 2 7 0 3 5 3 8 3 5 1 7]\n"
     ]
    }
   ],
   "source": [
    "# class SimpleDenseNN(nn.Module):\n",
    "#     def __init__(self, num_layers, neurons_per_layer):\n",
    "#         super(SimpleDenseNN, self).__init__()\n",
    "        \n",
    "#         # Create a list to hold the layers\n",
    "#         layers = []\n",
    "        \n",
    "#         # Input size for the first layer\n",
    "#         input_size = 3 * 32 * 32  # Assuming input images are flattened (3 channels, 32x32 pixels)\n",
    "        \n",
    "#         # Create the specified number of layers\n",
    "#         for i in range(num_layers):\n",
    "#             layers.append(nn.Linear(input_size, neurons_per_layer))  # Add a dense layer\n",
    "#             layers.append(nn.ReLU())  # Add ReLU activation\n",
    "#             input_size = neurons_per_layer  # Update input size for the next layer\n",
    "        \n",
    "#         # Add the output layer\n",
    "#         layers.append(nn.Linear(neurons_per_layer, 10))  # Assuming 10 output classes for CIFAR-10\n",
    "        \n",
    "#         # Combine all layers into a sequential model\n",
    "#         self.model = nn.Sequential(*layers)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = x.view(x.size(0), -1)  # Flatten the input tensor\n",
    "#         return self.model(x)  # Forward pass through the model\n",
    "\n",
    "# # Example usage\n",
    "# num_layers = 3  # Desired number of layers\n",
    "# neurons_per_layer = 128  # Desired number of neurons per layer\n",
    "# model = SimpleDenseNN(num_layers, neurons_per_layer)\n",
    "\n",
    "# # Print the model architecture\n",
    "# # print(model)\n",
    "\n",
    "# # Create an instance of the model\n",
    "# model = SimpleDenseNN(num_layers=3, neurons_per_layer=2)\n",
    "\n",
    "# # Define a loss function and optimizer\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# # Training loop\n",
    "# num_epochs = 5  # Number of epochs to train\n",
    "# for epoch in range(num_epochs):\n",
    "#     running_loss = 0.0\n",
    "#     for i, data in enumerate(train_loader, 0):\n",
    "#         inputs, labels = data\n",
    "#         optimizer.zero_grad()   # Zero the parameter gradients\n",
    "#         outputs = model(inputs) # Forward pass\n",
    "#         loss = criterion(outputs, labels) # Compute loss\n",
    "#         loss.backward()         # Backward pass\n",
    "#         optimizer.step()        # Optimize the weights\n",
    "#         running_loss += loss.item()\n",
    "        \n",
    "#         if i % 100 == 99:    # Print every 100 mini-batches\n",
    "#             print(f'Epoch {epoch + 1}, Batch {i + 1}, Loss: {running_loss / 100:.3f}')\n",
    "#             running_loss = 0.0\n",
    "\n",
    "# print('Finished Training')\n",
    "\n",
    "# # Save the model (optional)\n",
    "# torch.save(model.state_dict(), 'simple_cnn.pth')\n",
    "\n",
    "# # Prediction on the test set\n",
    "# correct = 0\n",
    "# total = 0\n",
    "# with torch.no_grad():  # No need to track gradients during evaluation\n",
    "#     for data in test_loader:\n",
    "#         images, labels = data\n",
    "#         outputs = model(images)  # Forward pass\n",
    "#         _, predicted = torch.max(outputs.data, 1)  # Get the predicted class\n",
    "#         total += labels.size(0)  # Update total count\n",
    "#         correct += (predicted == labels).sum().item()  # Update correct count\n",
    "\n",
    "# print(f'Accuracy of the model on the 10000 test images: {100 * correct / total:.2f}%')\n",
    "\n",
    "# # Print predicted labels\n",
    "# outputs = model(images)\n",
    "# _, predicted = torch.max(outputs, 1)\n",
    "# print('Predicted labels:', predicted.numpy())\n",
    "# print('True labels:', labels.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Define the number of layers and neurons per layer\n",
    "# num_layers = 3  # Number of layers\n",
    "# neurons_per_layer = 2  # Number of neurons in each layer\n",
    "\n",
    "# # Create a list to hold the layers\n",
    "# layers = []\n",
    "\n",
    "# # Input size for the first layer\n",
    "# input_size = 2\n",
    "\n",
    "# # Create layers in a loop\n",
    "# for _ in range(num_layers):\n",
    "#     layer = nn.Linear(input_size, neurons_per_layer)\n",
    "#     layers.append(layer)\n",
    "#     # Update input_size for the next layer\n",
    "#     input_size = neurons_per_layer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AutoML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
